{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pocket_url(endpoint):\n",
    "    return \"https://getpocket.com/v3/\" + endpoint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def scrape_and_tag_articles(csv_path: str, ):\n",
    "\n",
    "    # 'cm_pocket_export_23-11-2020.csv'\n",
    "    data=pd.read_csv(args.pocket_csv_input, index_col=0)\n",
    "    print(\"Input data Info: \\n\", data.info())\n",
    "\n",
    "    #when scraping all articles\n",
    "    solution = data\n",
    "\n",
    "    if args.causes_only:\n",
    "        solution_index=[]\n",
    "        for index,row in data.iterrows():\n",
    "            tags=row['tags']\n",
    "            if 'cause'in tags:\n",
    "                solution_index.append(index)\n",
    "            elif 'causes' in tags:\n",
    "                solution_index.append(index)\n",
    "            elif 'Cause' in tags:\n",
    "                solution_index.append(index)\n",
    "            elif 'Causes' in tags:\n",
    "                solution_index.append(index)\n",
    "            elif 'caused' in tags:\n",
    "                solution_index.append(index)\n",
    "            elif 'causing' in tags:\n",
    "                solution_index.append(index)\n",
    "\n",
    "        solution=data.loc[solution_index]\n",
    "\n",
    "    fb_string='https://www.facebook.com/'\n",
    "    fb_solution_index=[]\n",
    "    for index,row in solution.iterrows():\n",
    "        if fb_string in row['given_url']:\n",
    "            fb_solution_index.append(index)\n",
    "\n",
    "    solution_wo_fb=solution.drop(index=fb_solution_index)\n",
    "\n",
    "    # XXX: Need better naming\n",
    "    solution_wo_fb.to_csv(path.join(args.output_dir, 'all_pocket.csv'))\n",
    "\n",
    "    articles=solution_wo_fb['resolved_url'].values.tolist()\n",
    "\n",
    "    token = args.diffbot_token\n",
    "    URL   = args.diffbot_url\n",
    "\n",
    "    #data_to_store=[]\n",
    "    #articles=solution_wo_fb['resolved_url'].values.tolist()\n",
    "    #arricles_processed=[]\n",
    "\n",
    "    for x in tqdm(range(2206, 3084)):\n",
    "        PARAMS = {'token':token,'url':articles[x]}\n",
    "        r = requests.get(url = URL, params = PARAMS)\n",
    "        data = r.json()\n",
    "        data_to_store.append(data)\n",
    "        arricles_processed.append(articles[x])\n",
    "\n",
    "    pickle.dump( data_to_store, open( path.join(args.output_dir, \"all_pocket.p\"), \"wb\" ) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def process_pocket_pickle():\n",
    "    #\"all_pocket_diffbot_extract.p\"\n",
    "    diffbot_extract_file = args.diffbot_extract_file\n",
    "    diffbot_extract      = open(diffbot_extract_file, \"rb\")\n",
    "    data                 = pickle.load(diffbot_extract)\n",
    "\n",
    "    # data[0]['objects'][0].keys()\n",
    "    # 'date', 'sentiment', 'images', 'author', 'estimatedDate', 'publisherRegion', 'icon', 'diffbotUri', 'siteName',\n",
    "    # 'type', 'title', 'tags', 'publisherCountry', 'humanLanguage', 'pageUrl', 'html', 'text'\n",
    "\n",
    "    # \"all_pocket_tag_annotations.csv\"\n",
    "    tags_file_path = args.tags_file_path\n",
    "\n",
    "    #read all pocket tag annotations csv file into pandas dataframe\n",
    "    tag_annotations = pd.read_csv(tags_file_path, sep = \"\\t\")\n",
    "\n",
    "    annotations_df = tag_annotations[[\"pageURL\",\"tags\"]]\n",
    "    annotations_df.tags = annotations_df[\"tags\"].apply(lambda x: x.strip('][').replace(\"'\",\"\").split(', '))\n",
    "\n",
    "    #resolve duplicates by merging them.\n",
    "    annotations_df = annotations_df.groupby(['pageURL']).agg(sum).reset_index()\n",
    "    unique_tag_annotations = annotations_df.copy()\n",
    "    unique_tag_annotations.tags = annotations_df['tags'].apply(lambda x: list(set(x)))\n",
    "\n",
    "    text_list = []\n",
    "\n",
    "    for article in data:\n",
    "\n",
    "        try:\n",
    "            article_json = article['objects']\n",
    "\n",
    "            if (article_json[0][\"type\"]):\n",
    "                doc_type = article_json[0][\"type\"]\n",
    "                if (doc_type == \"article\"):\n",
    "                    text     = article_json[0][\"text\"]\n",
    "                    url      = article_json[0][\"pageUrl\"]\n",
    "                    title    = article_json[0][\"title\"]\n",
    "                    siteName = article_json[0][\"siteName\"]\n",
    "\n",
    "                    diffbot_tags = get_if_exists(article_json[0], \"tags\")\n",
    "                    unique_id    = get_if_exists(article_json[0], \"diffbotUri\")\n",
    "                    date         = get_if_exists(article_json[0], \"date\")\n",
    "                    author       = get_if_exists(article_json[0], \"author\")\n",
    "\n",
    "                    if (url in unique_tag_annotations['pageURL'].tolist()):\n",
    "                        pocket_tags = unique_tag_annotations.loc[unique_tag_annotations['pageURL'] == url , \"tags\"].tolist()[0]\n",
    "\n",
    "                    if (pocket_tags):\n",
    "                        items = {\"text\" : text, \"title\" : title, \"diffbot_tags\": diffbot_tags, \\\n",
    "                                 \"date\": date, \"author\": author, \"siteName\": siteName, \\\n",
    "                                 \"unique_id\": unique_id, \"url\": url, \"doc_type\": doc_type,\\\n",
    "                                 \"pocket_tags\": \", \".join(pocket_tags)}\n",
    "                    else:\n",
    "                        items = {\"text\" : text, \"title\" : title, \"diffbot_tags\": diffbot_tags, \\\n",
    "                                 \"date\": date, \"author\": author, \"siteName\": siteName, \\\n",
    "                                 \"unique_id\": unique_id, \"url\": url, \"doc_type\": doc_type}\n",
    "\n",
    "                    # example tag: effects\n",
    "                    if (args.tag_only):\n",
    "                        if(pocket_tags and args.tag_only in pocket_tags):\n",
    "                            text_list.append(items)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            print(\"Article: \", article, \"\\n\")\n",
    "\n",
    "    with open(args.output_file_path, 'w') as f:\n",
    "        for item in text_list:\n",
    "            f.write(json.dumps(item) + \"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}