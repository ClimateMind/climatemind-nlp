{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#convert data to longform. only take 'change_direction', 'type_of', 'base', 'aspect_changing', 'text'\n",
    "#for each entity that has multiples, expand the concept into multiple rows with each possible permutation (uses Cartesian product)\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import spacy\n",
    "import srsly\n",
    "\n",
    "\n",
    "#read in csv file\n",
    "data_set_name = \"checkin\"\n",
    "file_path = \"/Users/kameronr/Documents/personal/climate change outreach/new uploads/NLP data/checkin_answers_concepts_export.csv\"\n",
    "data = pd.read_csv(file_path) \n",
    "\n",
    "all_rows = []\n",
    "\n",
    "#make sure read it in correctly! As of now it's reading in the square brackets as strings and not as list items!\n",
    "#funciton to process element of dataframe\n",
    "def process_element(entry):\n",
    "\tresult = [thing.strip(\"'\") for thing in entry.strip(\"[|]\").split(', ')]\n",
    "\treturn result\n",
    "\n",
    "data = data.applymap(process_element)\n",
    "\n",
    "\n",
    "#for each row in the pandas dataframe... and build new dataframe\n",
    "#for index, row in df.iterrows():\n",
    "for row in data.itertuples():\n",
    "\tchange_direction = getattr(row, \"change_direction\")\n",
    "\ttype_of = getattr(row, \"type_of\")\n",
    "\tbase = getattr(row, \"base\")\n",
    "\taspect_changing = getattr(row, \"aspect_changing\")\n",
    "\n",
    "\tto_whom = getattr(row, \"to_whom\")[0]\n",
    "\teffect_size = getattr(row, \"effect_size\")[0]\n",
    "\tconfidence = getattr(row, \"confidence\")[0]\n",
    "\twhere = getattr(row, \"where\")[0]\n",
    "\twhen = getattr(row, \"when\")[0]\n",
    "\tpredicate = getattr(row, \"predicate\")[0]\n",
    "\t\n",
    "\ttext = getattr(row, \"text\")[0]\n",
    "\toriginal_text = getattr(row, \"original_text\")[0]\n",
    "\tsource = getattr(row, \"source\")[0]\n",
    "\tdocument_id = getattr(row, \"document_id\")[0]\n",
    "\tsentence_id = getattr(row, \"sentence_id\")[0]\n",
    "\tusername = getattr(row, \"username\")[0]\n",
    "\tflag = getattr(row, \"flag\")[0]\n",
    "\n",
    "\t#new_rows_tuple = product(change_direction, type_of, base, aspect_changing)\n",
    "\tnew_rows = (list(tup) for tup in product(change_direction, type_of, base, aspect_changing))\n",
    "\tnew_rows_nice = list(new_rows)\n",
    "\n",
    " \t#for i in range(len(new_rows)):\n",
    " \t#new_rows[i] = new_rows[i].extend([\n",
    "\tfor i in new_rows_nice:\n",
    " \t\ti.extend([\n",
    " \t\t\tto_whom, \n",
    " \t\t\teffect_size, \n",
    " \t\t\tconfidence, \n",
    " \t\t\twhere, \n",
    " \t\t\twhen, \n",
    " \t\t\tpredicate, \n",
    " \t\t\ttext, \n",
    " \t\t\toriginal_text, \n",
    " \t\t\tsource, \n",
    " \t\t\tdocument_id, \n",
    " \t\t\tsentence_id, \n",
    " \t\t\tusername, \n",
    " \t\t\tflag\n",
    " \t\t\t])\n",
    " \t\tall_rows.append(i)\n",
    "\n",
    "\n",
    "row_names = pd.Series([\n",
    "'change_direction', \n",
    "'type_of', \n",
    "'base', \n",
    "'aspect_changing',\n",
    "\n",
    "'to_whom',\n",
    "'effect_size',\n",
    "'confidence',\n",
    "'where',\n",
    "'when',\n",
    "'predicate',\n",
    "\n",
    "'text',\n",
    "'original_text',\n",
    "'source',\n",
    "'document_id',\n",
    "'sentence_id',\n",
    "'username',\n",
    "'flag'\n",
    "])\n",
    "\n",
    "core_concept_entities = ['change_direction', 'type_of', 'base', 'aspect_changing']\n",
    "everything_not_core_concept_related = row_names[row_names.isin(core_concept_entities) == False]\n",
    "\n",
    "#make lengthened dataframe that doesn't have lists for values\n",
    "df = pd.DataFrame(all_rows, columns=row_names)\n",
    "\n",
    "#convert to longform data \n",
    "longform_data = pd.melt(df, \n",
    "\tid_vars = everything_not_core_concept_related,\n",
    "\tvalue_vars = core_concept_entities ,\n",
    "\tvar_name = \"core_concept_entity\",\n",
    "\tvalue_name = \"phrase\" )\n",
    "\n",
    "#run diversity analysis\n",
    "grouped = longform_data.groupby(by=[\"core_concept_entity\", \"phrase\"], as_index=False)\n",
    "#count how many unique 'text' fields represented in each and save the output\n",
    "diversity_counts = grouped[['text']].nunique()\n",
    "\n",
    "#save results\n",
    "diversity_counts.to_csv(data_set_name+\"_diversity_counts.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}