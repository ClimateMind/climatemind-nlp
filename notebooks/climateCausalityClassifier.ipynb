{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "climateCausalityClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI4ZWfTxerCT"
      },
      "source": [
        "import os"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP0D9QGClMYY",
        "outputId": "a99dd14e-40cd-42dd-87d4-c395f56e7b5a"
      },
      "source": [
        "print(os.getcwd())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/climateMind\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sT8DRwGlPxG"
      },
      "source": [
        "os.chdir('SemEval')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_yd923TlVRG",
        "outputId": "efd49179-9944-42c2-dc8b-325467434334"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['semeval_2010_extracted_train_data.csv',\n",
              " 'semeval_2007_extracted_train_data.csv',\n",
              " 'semeval_2010_extracted_test_data.csv',\n",
              " 'semeval_2007_extracted_test_data.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5XUDC1OlYKf"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwRk6Bj2ld72"
      },
      "source": [
        "df = pd.read_csv('semeval_2010_extracted_train_data.csv', delimiter=';')\r\n",
        "df2 = pd.read_csv('semeval_2007_extracted_train_data.csv', delimiter=';')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xja8YN56lyl-",
        "outputId": "23fa7ff3-5664-4162-b14f-e7aaffcd9200"
      },
      "source": [
        "type(df.iloc[0]['Sentence'])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3xkD4ZrRl8Md",
        "outputId": "0a668f7f-0310-4b8e-acaa-aa1735daeee4"
      },
      "source": [
        "df.sample(50)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Relation</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>When you strike someone with a bottle full of ...</td>\n",
              "      <td>Content-Container(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6651</th>\n",
              "      <td>Air pollution from coal fired sources is so se...</td>\n",
              "      <td>Cause-Effect(e2,e1)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2867</th>\n",
              "      <td>The government's plans for the future of commu...</td>\n",
              "      <td>Message-Topic(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>This is made possible by unscrewing the three ...</td>\n",
              "      <td>Component-Whole(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7061</th>\n",
              "      <td>In the poem, the author develops the metaphysi...</td>\n",
              "      <td>Product-Producer(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2180</th>\n",
              "      <td>The weapon was hidden in what appears to be a ...</td>\n",
              "      <td>Content-Container(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The current view is that the chronic inflammat...</td>\n",
              "      <td>Cause-Effect(e2,e1)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6417</th>\n",
              "      <td>The first British steam powered vibrator dates...</td>\n",
              "      <td>Product-Producer(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6321</th>\n",
              "      <td>Operation Homefront and partners delivered toy...</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1711</th>\n",
              "      <td>We derive a pair of optimal weights on the dol...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6066</th>\n",
              "      <td>We placed the burlap into the bucket as lining.</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4711</th>\n",
              "      <td>A trillion gallons of water have been poured i...</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3041</th>\n",
              "      <td>It is a branch of philosophy dealing with the ...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2097</th>\n",
              "      <td>He released the brake cable by detaching the r...</td>\n",
              "      <td>Component-Whole(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5507</th>\n",
              "      <td>Crime fiction is the genre of fiction that dea...</td>\n",
              "      <td>Message-Topic(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021</th>\n",
              "      <td>A pack of the most popular cigarettes in the S...</td>\n",
              "      <td>Content-Container(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6644</th>\n",
              "      <td>An organization with the mission of allowing a...</td>\n",
              "      <td>Cause-Effect(e2,e1)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7378</th>\n",
              "      <td>The findings clearly show a high level of sati...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1173</th>\n",
              "      <td>A state church is created by the state, as in ...</td>\n",
              "      <td>Product-Producer(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>A Boy Scout in North Carolina found a purse wi...</td>\n",
              "      <td>Content-Container(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>Symptoms vary according to the degree of infla...</td>\n",
              "      <td>Cause-Effect(e2,e1)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2344</th>\n",
              "      <td>In this constitution the people was the source...</td>\n",
              "      <td>Entity-Origin(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1610</th>\n",
              "      <td>The reconstitution of boards of governors take...</td>\n",
              "      <td>Member-Collection(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1461</th>\n",
              "      <td>Teetotallers zip over the Causeway in the mids...</td>\n",
              "      <td>Member-Collection(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4410</th>\n",
              "      <td>In order to gather experimental data, research...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4479</th>\n",
              "      <td>Malaria is caused by infection with a parasite...</td>\n",
              "      <td>Cause-Effect(e2,e1)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>In the healthy heart, the left ventricle perfo...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1790</th>\n",
              "      <td>The vagina was sutured behind the neourethra; ...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5948</th>\n",
              "      <td>This machine was in a suitcase that was the si...</td>\n",
              "      <td>Content-Container(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5735</th>\n",
              "      <td>Ants are spreading into new habitats.</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>Quality forged pinking scissors cut with excep...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7201</th>\n",
              "      <td>It is a family luxury villa with breeze-kissed...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>A Channel 4 drama set in a psychiatric unit ha...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4938</th>\n",
              "      <td>The film details plastic's path over the last ...</td>\n",
              "      <td>Message-Topic(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6322</th>\n",
              "      <td>The term has been used by a number of publicat...</td>\n",
              "      <td>Message-Topic(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2188</th>\n",
              "      <td>The cold temperature waves are flowing into th...</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6616</th>\n",
              "      <td>Cream of mushroom soup was first made availabl...</td>\n",
              "      <td>Entity-Origin(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>The two populations started from the same gene...</td>\n",
              "      <td>Entity-Origin(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5868</th>\n",
              "      <td>I'm going with some girls to get a bunch of fl...</td>\n",
              "      <td>Member-Collection(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5116</th>\n",
              "      <td>There is an exhaust vent and a cable to start ...</td>\n",
              "      <td>Instrument-Agency(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5157</th>\n",
              "      <td>In the present study, we adapted a battery of ...</td>\n",
              "      <td>Member-Collection(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4847</th>\n",
              "      <td>First of all, it is a source of specialist cad...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5746</th>\n",
              "      <td>The immediate post-war years were a hive of id...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>The supreme court has applied the protections ...</td>\n",
              "      <td>Instrument-Agency(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>Down the winding path which curved among the r...</td>\n",
              "      <td>Member-Collection(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>In the book, the main female character is a wo...</td>\n",
              "      <td>Message-Topic(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6741</th>\n",
              "      <td>The association keeps teachers informed about ...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>While the job was good, Ahmed's daily exposure...</td>\n",
              "      <td>Member-Collection(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4779</th>\n",
              "      <td>Allegations were made about Galloway's persona...</td>\n",
              "      <td>Message-Topic(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176</th>\n",
              "      <td>The e-mail was sent from the private account o...</td>\n",
              "      <td>Entity-Origin(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Sentence  ... Label\n",
              "266   When you strike someone with a bottle full of ...  ...     0\n",
              "6651  Air pollution from coal fired sources is so se...  ...     1\n",
              "2867  The government's plans for the future of commu...  ...     0\n",
              "932   This is made possible by unscrewing the three ...  ...     0\n",
              "7061  In the poem, the author develops the metaphysi...  ...     0\n",
              "2180  The weapon was hidden in what appears to be a ...  ...     0\n",
              "6     The current view is that the chronic inflammat...  ...     1\n",
              "6417  The first British steam powered vibrator dates...  ...     0\n",
              "6321  Operation Homefront and partners delivered toy...  ...     0\n",
              "1711  We derive a pair of optimal weights on the dol...  ...     0\n",
              "6066    We placed the burlap into the bucket as lining.  ...     0\n",
              "4711  A trillion gallons of water have been poured i...  ...     0\n",
              "3041  It is a branch of philosophy dealing with the ...  ...     0\n",
              "2097  He released the brake cable by detaching the r...  ...     0\n",
              "5507  Crime fiction is the genre of fiction that dea...  ...     0\n",
              "2021  A pack of the most popular cigarettes in the S...  ...     0\n",
              "6644  An organization with the mission of allowing a...  ...     1\n",
              "7378  The findings clearly show a high level of sati...  ...     0\n",
              "1173  A state church is created by the state, as in ...  ...     0\n",
              "1759  A Boy Scout in North Carolina found a purse wi...  ...     0\n",
              "1516  Symptoms vary according to the degree of infla...  ...     1\n",
              "2344  In this constitution the people was the source...  ...     0\n",
              "1610  The reconstitution of boards of governors take...  ...     0\n",
              "1461  Teetotallers zip over the Causeway in the mids...  ...     0\n",
              "4410  In order to gather experimental data, research...  ...     0\n",
              "4479  Malaria is caused by infection with a parasite...  ...     1\n",
              "3404  In the healthy heart, the left ventricle perfo...  ...     0\n",
              "1790  The vagina was sutured behind the neourethra; ...  ...     0\n",
              "5948  This machine was in a suitcase that was the si...  ...     0\n",
              "5735              Ants are spreading into new habitats.  ...     0\n",
              "7263  Quality forged pinking scissors cut with excep...  ...     0\n",
              "7201  It is a family luxury villa with breeze-kissed...  ...     0\n",
              "835   A Channel 4 drama set in a psychiatric unit ha...  ...     0\n",
              "4938  The film details plastic's path over the last ...  ...     0\n",
              "6322  The term has been used by a number of publicat...  ...     0\n",
              "2188  The cold temperature waves are flowing into th...  ...     0\n",
              "6616  Cream of mushroom soup was first made availabl...  ...     0\n",
              "762   The two populations started from the same gene...  ...     0\n",
              "5868  I'm going with some girls to get a bunch of fl...  ...     0\n",
              "5116  There is an exhaust vent and a cable to start ...  ...     0\n",
              "5157  In the present study, we adapted a battery of ...  ...     0\n",
              "4847  First of all, it is a source of specialist cad...  ...     0\n",
              "5746  The immediate post-war years were a hive of id...  ...     0\n",
              "421   The supreme court has applied the protections ...  ...     0\n",
              "1366  Down the winding path which curved among the r...  ...     0\n",
              "2005  In the book, the main female character is a wo...  ...     0\n",
              "6741  The association keeps teachers informed about ...  ...     0\n",
              "504   While the job was good, Ahmed's daily exposure...  ...     0\n",
              "4779  Allegations were made about Galloway's persona...  ...     0\n",
              "1176  The e-mail was sent from the private account o...  ...     0\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LqUnDganmo2N",
        "outputId": "017afb03-774a-49a1-9bc0-0e16da1d895e"
      },
      "source": [
        "df2.sample(50)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Relation</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>Tou should use a screwdriver to tighten the bo...</td>\n",
              "      <td>WordNet(e1) = \"screwdriver%1:06:00::\", WordNet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>The event featured a demonstration of weaving ...</td>\n",
              "      <td>WordNet(e1) = \"loom%1:06:00::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>Located near the equator in South America, the...</td>\n",
              "      <td>WordNet(e1) = \"tree%1:20:00::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>Lowering your blood sugar is the key to managi...</td>\n",
              "      <td>WordNet(e1) = \"blood%1:08:00::\", WordNet(e2) =...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>The process for obtaining a visa depends on wh...</td>\n",
              "      <td>WordNet(e1) = \"process%1:04:00::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>The design of the shape of the can ends moreov...</td>\n",
              "      <td>WordNet(e1) = \"deformation%1:11:01::\", WordNet...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>Villagers live in constant terror of indiscrim...</td>\n",
              "      <td>WordNet(e1) = \"terror%1:12:00::\", WordNet(e2) ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>The kitchen contained one other interesting it...</td>\n",
              "      <td>WordNet(e1) = \"kitchen%1:06:00::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>Myles and Simpson also identify defensive beha...</td>\n",
              "      <td>WordNet(e1) = \"behaviour%1:07:00::\", WordNet(e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>The simulation study produces voluminous resul...</td>\n",
              "      <td>WordNet(e1) = \"study%1:04:00::\", WordNet(e2) =...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>What did the residents and scientists learn fr...</td>\n",
              "      <td>WordNet(e1) = \"scientist%1:18:00::\", WordNet(e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>I am installing lights under the cabinets in m...</td>\n",
              "      <td>WordNet(e1) = \"cabinet%1:06:02::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>Delay and procrastination set you up for frust...</td>\n",
              "      <td>WordNet(e1) = \"frustration%1:12:00::\", WordNet...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>We provide test preparers with a platform for ...</td>\n",
              "      <td>WordNet(e1) = \"platform%1:06:03::\", WordNet(e2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>When the taxi driver stopped his car and got o...</td>\n",
              "      <td>WordNet(e1) = \"driver%1:18:00::\", WordNet(e2) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>Chicken bouillon can be obtained in three diff...</td>\n",
              "      <td>WordNet(e1) = \"chicken%1:13:00::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>The Norwalk juicer grinds and presses any frui...</td>\n",
              "      <td>WordNet(e1) = \"juicer%1:06:00::\", WordNet(e2) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>768</th>\n",
              "      <td>In the most common form of such an attack, cal...</td>\n",
              "      <td>WordNet(e1) = \"blockage%1:26:00::\", WordNet(e2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>The guarantees so painfully obtained by formal...</td>\n",
              "      <td>WordNet(e1) = \"compiler%1:10:00::\", WordNet(e2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>This surgical operation isolates most of the r...</td>\n",
              "      <td>WordNet(e1) = \"right_hemisphere%1:08:00::\", Wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>Some inactivated influenza vaccine contains th...</td>\n",
              "      <td>WordNet(e1) = \"preservative%1:27:00::\", WordNe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>Scientific progress comes from breakthroughs a...</td>\n",
              "      <td>WordNet(e1) = \"progress%1:04:01::\", WordNet(e2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>One newly formed Iraqi battalion is on duty, w...</td>\n",
              "      <td>WordNet(e1) = \"activation%1:04:00::\", WordNet(...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>Original works of authorship were fixed in a t...</td>\n",
              "      <td>WordNet(e1) = \"works%1:06:00::\", WordNet(e2) =...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>Agarwood, the world's most valuable incense, i...</td>\n",
              "      <td>WordNet(e1) = \"?\", WordNet(e2) = \"tree%1:20:00...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>The actor played a psychopathic preacher with ...</td>\n",
              "      <td>WordNet(e1) = \"actor%1:18:00::\", WordNet(e2) =...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>This program will be an effective step to miti...</td>\n",
              "      <td>WordNet(e1) = \"damage%1:11:00::\", WordNet(e2) ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>This information is used for tracking down err...</td>\n",
              "      <td>WordNet(e1) = \"information%1:14:00::\", WordNet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>I mentioned some time ago that our tendency is...</td>\n",
              "      <td>WordNet(e1) = \"tendency%1:09:00::\", WordNet(e2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>Many games can be played with Go equipment.</td>\n",
              "      <td>WordNet(e1) = \"game%1:04:00::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>I was only thirteen, and they were going to ha...</td>\n",
              "      <td>WordNet(e1) = \"window%1:06:05::\", WordNet(e2) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>The Group's influence was so widespread by the...</td>\n",
              "      <td>WordNet(e1) = \"group%1:03:00::\", WordNet(e2) =...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>Normally, the bone marrow produces stem cells ...</td>\n",
              "      <td>WordNet(e1) = \"bone_marrow%1:08:00::\", WordNet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>Different from the curry source, chicken bouil...</td>\n",
              "      <td>WordNet(e1) = \"bouillon%1:13:00::\", WordNet(e2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>We can make rolling easier and more effective ...</td>\n",
              "      <td>WordNet(e1) = \"rolling%1:04:00::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>The physician bill is from the physician who p...</td>\n",
              "      <td>WordNet(e1) = \"bill%1:10:01::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>And of course the original development that en...</td>\n",
              "      <td>WordNet(e1) = \"split%1:04:00::\", WordNet(e2) =...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>The purpose of this Guide is to provide you wi...</td>\n",
              "      <td>WordNet(e1) = \"purpose%1:09:00::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>The remarkably comprehensive 32-page 2004 Memo...</td>\n",
              "      <td>WordNet(e1) = \"candidate%1:18:01::\", WordNet(e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>So you are not only sharing the speaker inform...</td>\n",
              "      <td>WordNet(e1) = \"audio%1:10:00::\", WordNet(e2) =...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>A light cheese full of rustic flavors, it wake...</td>\n",
              "      <td>WordNet(e1) = \"cheese%1:13:00::\", WordNet(e2) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>They understand the stakes from a personal per...</td>\n",
              "      <td>WordNet(e1) = \"stakes%1:21:00::\", WordNet(e2) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>The homes are from a simpler time, when closet...</td>\n",
              "      <td>WordNet(e1) = \"home%1:06:00::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>The rest of the points are awarded proportiona...</td>\n",
              "      <td>WordNet(e1) = \"ball%1:06:01::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>If governments were once content to passively ...</td>\n",
              "      <td>WordNet(e1) = \"benefit%1:07:00::\", WordNet(e2)...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>The ball is retrieved from the hedge.</td>\n",
              "      <td>WordNet(e1) = \"ball%1:06:01::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>The age of first marriage does not predict hap...</td>\n",
              "      <td>WordNet(e1) = \"happiness%1:26:00::\", WordNet(e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>PHY 319 is presently taught in three 50-minute...</td>\n",
              "      <td>WordNet(e1) = \"instructor%1:18:00::\", WordNet(...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>In summer 2000, an Adventist church in Polotsk...</td>\n",
              "      <td>WordNet(e1) = \"fire%1:11:00::\", WordNet(e2) = ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>Sitting by the beach, Yuki mended the net whil...</td>\n",
              "      <td>WordNet(e1) = \"net%1:06:02::\", WordNet(e2) = \"...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Label\n",
              "202  Tou should use a screwdriver to tighten the bo...  ...     0\n",
              "188  The event featured a demonstration of weaving ...  ...     0\n",
              "540  Located near the equator in South America, the...  ...     0\n",
              "351  Lowering your blood sugar is the key to managi...  ...     0\n",
              "863  The process for obtaining a visa depends on wh...  ...     0\n",
              "765  The design of the shape of the can ends moreov...  ...     1\n",
              "815  Villagers live in constant terror of indiscrim...  ...     1\n",
              "623  The kitchen contained one other interesting it...  ...     0\n",
              "767  Myles and Simpson also identify defensive beha...  ...     1\n",
              "430  The simulation study produces voluminous resul...  ...     0\n",
              "354  What did the residents and scientists learn fr...  ...     0\n",
              "604  I am installing lights under the cabinets in m...  ...     0\n",
              "752  Delay and procrastination set you up for frust...  ...     1\n",
              "840  We provide test preparers with a platform for ...  ...     0\n",
              "172  When the taxi driver stopped his car and got o...  ...     0\n",
              "375  Chicken bouillon can be obtained in three diff...  ...     0\n",
              "203  The Norwalk juicer grinds and presses any frui...  ...     0\n",
              "768  In the most common form of such an attack, cal...  ...     1\n",
              "298  The guarantees so painfully obtained by formal...  ...     0\n",
              "406  This surgical operation isolates most of the r...  ...     0\n",
              "698  Some inactivated influenza vaccine contains th...  ...     0\n",
              "808  Scientific progress comes from breakthroughs a...  ...     1\n",
              "709  One newly formed Iraqi battalion is on duty, w...  ...     1\n",
              "106  Original works of authorship were fixed in a t...  ...     0\n",
              "508  Agarwood, the world's most valuable incense, i...  ...     0\n",
              "175  The actor played a psychopathic preacher with ...  ...     0\n",
              "806  This program will be an effective step to miti...  ...     1\n",
              "969  This information is used for tracking down err...  ...     0\n",
              "879  I mentioned some time ago that our tendency is...  ...     0\n",
              "233        Many games can be played with Go equipment.  ...     0\n",
              "85   I was only thirteen, and they were going to ha...  ...     0\n",
              "127  The Group's influence was so widespread by the...  ...     0\n",
              "548  Normally, the bone marrow produces stem cells ...  ...     0\n",
              "358  Different from the curry source, chicken bouil...  ...     0\n",
              "214  We can make rolling easier and more effective ...  ...     0\n",
              "280  The physician bill is from the physician who p...  ...     0\n",
              "10   And of course the original development that en...  ...     0\n",
              "934  The purpose of this Guide is to provide you wi...  ...     0\n",
              "383  The remarkably comprehensive 32-page 2004 Memo...  ...     0\n",
              "350  So you are not only sharing the speaker inform...  ...     0\n",
              "77   A light cheese full of rustic flavors, it wake...  ...     0\n",
              "333  They understand the stakes from a personal per...  ...     0\n",
              "409  The homes are from a simpler time, when closet...  ...     0\n",
              "408  The rest of the points are awarded proportiona...  ...     0\n",
              "761  If governments were once content to passively ...  ...     1\n",
              "389              The ball is retrieved from the hedge.  ...     0\n",
              "716  The age of first marriage does not predict hap...  ...     1\n",
              "524  PHY 319 is presently taught in three 50-minute...  ...     0\n",
              "733  In summer 2000, an Adventist church in Polotsk...  ...     1\n",
              "234  Sitting by the beach, Yuki mended the net whil...  ...     0\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXBiGt_dmtf-",
        "outputId": "ce69c237-08fc-4b7c-b768-80f3b6435e57"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Get the GPU device name.\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "\r\n",
        "# The device name should look like the following:\r\n",
        "if device_name == '/device:GPU:0':\r\n",
        "    print('Found GPU at: {}'.format(device_name))\r\n",
        "else:\r\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQXDc1Xvn7QA",
        "outputId": "2473adf6-e682-4ae0-d253-83d13b5943a6"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "# If there's a GPU available...\r\n",
        "if torch.cuda.is_available():    \r\n",
        "\r\n",
        "    # Tell PyTorch to use the GPU.    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "# If not...\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3taU9EYoAWF",
        "outputId": "032fc5fe-469f-46cf-b011-77b3afeabeaa"
      },
      "source": [
        "!pip install transformers==3"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 8.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=b2f627ef9c454c87192fefad0b0a0b8efeb649b8b5400ca85beb37fb7fe16bd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmOx2fvkoEot"
      },
      "source": [
        "df_train=df.append(df2, ignore_index=True)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8B9dol6ofBV",
        "outputId": "b9c0996d-4add-4de3-ba94-2606249d4b70"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hSoyB3dolB8",
        "outputId": "0cf24c57-c4ce-476a-e51d-156c9efb102d"
      },
      "source": [
        "len(df2)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYRI0-UKuWT7",
        "outputId": "7532d442-0706-4931-97f4-b6cbddd19c63"
      },
      "source": [
        "len(df_train)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "TLGvtLu7ozR0",
        "outputId": "abf89941-fafe-4995-f284-858ae3b84bee"
      },
      "source": [
        "df_train.sample(30)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Relation</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8242</th>\n",
              "      <td>The surgeon cuts a small hole in the skull and...</td>\n",
              "      <td>WordNet(e1) = \"surgeon%1:18:00::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6525</th>\n",
              "      <td>I have already fetched the mail into my accoun...</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2841</th>\n",
              "      <td>The toy was inside a box and had been left on ...</td>\n",
              "      <td>Content-Container(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7885</th>\n",
              "      <td>The total contents of the purse included a cel...</td>\n",
              "      <td>Content-Container(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7290</th>\n",
              "      <td>The architect carefully designed the 15 rowhou...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7955</th>\n",
              "      <td>The box holds all our empty promises to give b...</td>\n",
              "      <td>Content-Container(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8757</th>\n",
              "      <td>The spiciness comes from small capsaicin gland...</td>\n",
              "      <td>WordNet(e1) = \"spiciness%1:07:00::\", WordNet(e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4505</th>\n",
              "      <td>Two years passed before I saw the ibex again, ...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>The executive board of this company reported o...</td>\n",
              "      <td>Component-Whole(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2781</th>\n",
              "      <td>The prisoner has been released into her new fa...</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8358</th>\n",
              "      <td>Different from the curry source, chicken bouil...</td>\n",
              "      <td>WordNet(e1) = \"bouillon%1:13:00::\", WordNet(e2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>Suppose you were given a bottle that contains ...</td>\n",
              "      <td>WordNet(e1) = \"bottle%1:06:00::\", WordNet(e2) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4466</th>\n",
              "      <td>For example, measles and chickenpox cause rash...</td>\n",
              "      <td>Cause-Effect(e1,e2)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4376</th>\n",
              "      <td>There are two important personalities among th...</td>\n",
              "      <td>Member-Collection(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>The answer to the inquiry was solicited from h...</td>\n",
              "      <td>Entity-Origin(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640</th>\n",
              "      <td>A person regains the movement roughly equal to...</td>\n",
              "      <td>Instrument-Agency(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8472</th>\n",
              "      <td>To better follow the quality, the company manu...</td>\n",
              "      <td>WordNet(e1) = \"company%1:14:01::\", WordNet(e2)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2688</th>\n",
              "      <td>Teacher Man is a 2005 memoir written by Frank ...</td>\n",
              "      <td>Message-Topic(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7730</th>\n",
              "      <td>The morning session contains a tutorial that a...</td>\n",
              "      <td>Component-Whole(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2096</th>\n",
              "      <td>A stereo buss outputs the stereo buss signal; ...</td>\n",
              "      <td>Cause-Effect(e1,e2)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>I have recently developed creases in my ear lo...</td>\n",
              "      <td>Component-Whole(e2,e1)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8874</th>\n",
              "      <td>In most part, it was another a plea for the st...</td>\n",
              "      <td>WordNet(e1) = \"plea%1:10:00::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8605</th>\n",
              "      <td>When he was back he noticed that he had locked...</td>\n",
              "      <td>WordNet(e1) = \"key%1:06:00::\", WordNet(e2) = \"...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1441</th>\n",
              "      <td>Heartwater disease was imported into the major...</td>\n",
              "      <td>Entity-Destination(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4317</th>\n",
              "      <td>Hardcore country cats are happy to live in the...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1711</th>\n",
              "      <td>We derive a pair of optimal weights on the dol...</td>\n",
              "      <td>Other\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8417</th>\n",
              "      <td>The dose makes the poison.</td>\n",
              "      <td>WordNet(e1) = \"dose%1:06:00::\", WordNet(e2) = ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6977</th>\n",
              "      <td>The cool fog of the summer morning had inundat...</td>\n",
              "      <td>Cause-Effect(e1,e2)\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8513</th>\n",
              "      <td>The tenant has farmed for this owner for sever...</td>\n",
              "      <td>WordNet(e1) = \"tenant%1:18:00::\", WordNet(e2) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>Salva Kiir gave a speech criticising the north...</td>\n",
              "      <td>Message-Topic(e1,e2)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Sentence  ... Label\n",
              "8242  The surgeon cuts a small hole in the skull and...  ...     0\n",
              "6525  I have already fetched the mail into my accoun...  ...     0\n",
              "2841  The toy was inside a box and had been left on ...  ...     0\n",
              "7885  The total contents of the purse included a cel...  ...     0\n",
              "7290  The architect carefully designed the 15 rowhou...  ...     0\n",
              "7955  The box holds all our empty promises to give b...  ...     0\n",
              "8757  The spiciness comes from small capsaicin gland...  ...     1\n",
              "4505  Two years passed before I saw the ibex again, ...  ...     0\n",
              "324   The executive board of this company reported o...  ...     0\n",
              "2781  The prisoner has been released into her new fa...  ...     0\n",
              "8358  Different from the curry source, chicken bouil...  ...     0\n",
              "8674  Suppose you were given a bottle that contains ...  ...     0\n",
              "4466  For example, measles and chickenpox cause rash...  ...     1\n",
              "4376  There are two important personalities among th...  ...     0\n",
              "4598  The answer to the inquiry was solicited from h...  ...     0\n",
              "640   A person regains the movement roughly equal to...  ...     0\n",
              "8472  To better follow the quality, the company manu...  ...     0\n",
              "2688  Teacher Man is a 2005 memoir written by Frank ...  ...     0\n",
              "7730  The morning session contains a tutorial that a...  ...     0\n",
              "2096  A stereo buss outputs the stereo buss signal; ...  ...     1\n",
              "160   I have recently developed creases in my ear lo...  ...     0\n",
              "8874  In most part, it was another a plea for the st...  ...     0\n",
              "8605  When he was back he noticed that he had locked...  ...     0\n",
              "1441  Heartwater disease was imported into the major...  ...     0\n",
              "4317  Hardcore country cats are happy to live in the...  ...     0\n",
              "1711  We derive a pair of optimal weights on the dol...  ...     0\n",
              "8417                         The dose makes the poison.  ...     0\n",
              "6977  The cool fog of the summer morning had inundat...  ...     1\n",
              "8513  The tenant has farmed for this owner for sever...  ...     0\n",
              "4843  Salva Kiir gave a speech criticising the north...  ...     0\n",
              "\n",
              "[30 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oxDNxBzvfbA"
      },
      "source": [
        "df_train = df_train[df_train['Sentence'].notna()]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDUKlA-KpNM0",
        "outputId": "76954c70-5f15-41a6-bdbb-7d41f9a11227"
      },
      "source": [
        "count = 0\r\n",
        "for x in range(0,len(df_train)):\r\n",
        "  if df_train.iloc[x]['Label']==1:\r\n",
        "    count+=1\r\n",
        "\r\n",
        "print(count)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ2XOztCuD4j"
      },
      "source": [
        "sentences = df_train.Sentence.values\r\n",
        "labels = df_train.Label.values"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK6gWRpru3FZ",
        "outputId": "56cc77bb-9791-4294-d68e-a7ddf45ffaa4"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "# Load the BERT tokenizer.\r\n",
        "print('Loading BERT tokenizer...')\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PliVaep3u5ih",
        "outputId": "8ca49f16-28e8-4384-cfb9-19f2ec36f1f1"
      },
      "source": [
        "# Print the original sentence.\r\n",
        "print(' Original: ', sentences[0])\r\n",
        "\r\n",
        "# Print the sentence split into tokens.\r\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\r\n",
        "\r\n",
        "# Print the sentence mapped to token ids.\r\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  The system as described above has its greatest application in an arrayed configuration of antenna elements.\n",
            "Tokenized:  ['the', 'system', 'as', 'described', 'above', 'has', 'its', 'greatest', 'application', 'in', 'an', 'array', '##ed', 'configuration', 'of', 'antenna', 'elements', '.']\n",
            "Token IDs:  [1996, 2291, 2004, 2649, 2682, 2038, 2049, 4602, 4646, 1999, 2019, 9140, 2098, 9563, 1997, 13438, 3787, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0eKUQNnvWtQ",
        "outputId": "e2151ecd-7066-4312-8340-1c37bb4de170"
      },
      "source": [
        "max_len = 0\r\n",
        "\r\n",
        "# For every sentence...\r\n",
        "for sent in sentences:\r\n",
        "\r\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\r\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\r\n",
        "\r\n",
        "    # Update the maximum sentence length.\r\n",
        "    max_len = max(max_len, len(input_ids))\r\n",
        "\r\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gATwFZGEvZA4",
        "outputId": "557e507b-99a1-4bf2-dd26-b3bdf138913a"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\r\n",
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# For every sentence...\r\n",
        "for sent in sentences:\r\n",
        "    # `encode_plus` will:\r\n",
        "    #   (1) Tokenize the sentence.\r\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\r\n",
        "    #   (3) Append the `[SEP]` token to the end.\r\n",
        "    #   (4) Map tokens to their IDs.\r\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\r\n",
        "    #   (6) Create attention masks for [PAD] tokens.\r\n",
        "    encoded_dict = tokenizer.encode_plus(\r\n",
        "                        sent,                      # Sentence to encode.\r\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\r\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\r\n",
        "                        pad_to_max_length = True,\r\n",
        "                        truncation=True,\r\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\r\n",
        "                   )\r\n",
        "    \r\n",
        "    # Add the encoded sentence to the list.    \r\n",
        "    input_ids.append(encoded_dict['input_ids'])\r\n",
        "    \r\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\r\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  The system as described above has its greatest application in an arrayed configuration of antenna elements.\n",
            "Token IDs: tensor([  101,  1996,  2291,  2004,  2649,  2682,  2038,  2049,  4602,  4646,\n",
            "         1999,  2019,  9140,  2098,  9563,  1997, 13438,  3787,  1012,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R85Kfq6j0pIV",
        "outputId": "d4798ba9-4d5c-4860-8b99-3e0994021f66"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\r\n",
        "\r\n",
        "# Combine the training inputs into a TensorDataset.\r\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "\r\n",
        "# Create a 90-10 train-validation split.\r\n",
        "\r\n",
        "# Calculate the number of samples to include in each set.\r\n",
        "train_size = int(0.9 * len(dataset))\r\n",
        "val_size = len(dataset) - train_size\r\n",
        "\r\n",
        "# Divide the dataset by randomly selecting samples.\r\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\r\n",
        "\r\n",
        "print('{:>5,} training samples'.format(train_size))\r\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8,074 training samples\n",
            "  898 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5uQzNAx0piG"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\r\n",
        "\r\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \r\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \r\n",
        "# size of 16 or 32.\r\n",
        "batch_size = 16\r\n",
        "\r\n",
        "# Create the DataLoaders for our training and validation sets.\r\n",
        "# We'll take training samples in random order. \r\n",
        "train_dataloader = DataLoader(\r\n",
        "            train_dataset,  # The training samples.\r\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\r\n",
        "            batch_size = batch_size # Trains with this batch size.\r\n",
        "        )\r\n",
        "\r\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\r\n",
        "validation_dataloader = DataLoader(\r\n",
        "            val_dataset, # The validation samples.\r\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\r\n",
        "            batch_size = batch_size # Evaluate with this batch size.\r\n",
        "        )"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mUnA8xn1EMs"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TQYN5Lj31Vrm",
        "outputId": "5e08ec68-624a-4826-d3e2-aa905bf5b5bf"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFrPMGC_1JgN"
      },
      "source": [
        "os.chdir('drive/MyDrive/ClimateBERT')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XrGP_0x01Tt",
        "outputId": "138ac8b0-3e53-4d0e-de8f-4d6c2eea3dc6"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "\r\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \r\n",
        "# linear classification layer on top. \r\n",
        "model = BertForSequenceClassification.from_pretrained(\r\n",
        "    \"pytorch\", # Use the 12-layer BERT model, with an uncased vocab.\r\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\r\n",
        "                    # You can increase this for multi-class tasks.   \r\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\r\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\r\n",
        ")\r\n",
        "\r\n",
        "# Tell pytorch to run this model on the GPU.\r\n",
        "#device = xm.xla_device()\r\n",
        "#model.to(device)\r\n",
        "model.cuda()\r\n",
        "\r\n",
        "print(device)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at pytorch were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pytorch and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr04yh-_1eUf"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \r\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\r\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\r\n",
        "                )\r\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBvDQkn71sfN"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \r\n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\r\n",
        "# training data.\r\n",
        "epochs = 4\r\n",
        "\r\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \r\n",
        "# (Note that this is not the same as the number of training samples).\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# Create the learning rate scheduler.\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eufPGc3w1weF"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# Function to calculate the accuracy of our predictions vs labels\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1Cgf94A1yeG"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "\r\n",
        "def format_time(elapsed):\r\n",
        "    '''\r\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\r\n",
        "    '''\r\n",
        "    # Round to the nearest second.\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # Format as hh:mm:ss\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9--Fx6s1z4t",
        "outputId": "a5e13376-abe1-4872-df65-612a9ff5a7f6"
      },
      "source": [
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# This training code is based on the `run_glue.py` script here:\r\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\r\n",
        "\r\n",
        "# Set the seed value all over the place to make this reproducible.\r\n",
        "seed_val = 42\r\n",
        "\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "# We'll store a number of quantities such as training and validation loss, \r\n",
        "# validation accuracy, and timings.\r\n",
        "training_stats = []\r\n",
        "\r\n",
        "# Measure the total training time for the whole run.\r\n",
        "total_t0 = time.time()\r\n",
        "\r\n",
        "# For each epoch...\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    # Perform one full pass over the training set.\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # Measure how long the training epoch takes.\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # Reset the total loss for this epoch.\r\n",
        "    total_train_loss = 0\r\n",
        "\r\n",
        "    # Put the model into training mode. Don't be mislead--the call to \r\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\r\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\r\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    # For each batch of training data...\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "\r\n",
        "        # Progress update every 40 batches.\r\n",
        "        if step % 40 == 0 and not step == 0:\r\n",
        "            # Calculate elapsed time in minutes.\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            \r\n",
        "            # Report progress.\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # Unpack this training batch from our dataloader. \r\n",
        "        #\r\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \r\n",
        "        # `to` method.\r\n",
        "        #\r\n",
        "        # `batch` contains three pytorch tensors:\r\n",
        "        #   [0]: input ids \r\n",
        "        #   [1]: attention masks\r\n",
        "        #   [2]: labels \r\n",
        "        b_input_ids = batch[0].to(device)\r\n",
        "        b_input_mask = batch[1].to(device)\r\n",
        "        b_labels = batch[2].to(device)\r\n",
        "\r\n",
        "        # Always clear any previously calculated gradients before performing a\r\n",
        "        # backward pass. PyTorch doesn't do this automatically because \r\n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \r\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\r\n",
        "        model.zero_grad()        \r\n",
        "\r\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\r\n",
        "        # The documentation for this `model` function is here: \r\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\r\n",
        "        # It returns different numbers of parameters depending on what arguments\r\n",
        "        # arge given and what flags are set. For our useage here, it returns\r\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\r\n",
        "        # outputs prior to activation.\r\n",
        "        loss, logits = model(b_input_ids, \r\n",
        "                             token_type_ids=None, \r\n",
        "                             attention_mask=b_input_mask, \r\n",
        "                             labels=b_labels)\r\n",
        "\r\n",
        "        # Accumulate the training loss over all of the batches so that we can\r\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\r\n",
        "        # single value; the `.item()` function just returns the Python value \r\n",
        "        # from the tensor.\r\n",
        "        total_train_loss += loss.item()\r\n",
        "\r\n",
        "        # Perform a backward pass to calculate the gradients.\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # Clip the norm of the gradients to 1.0.\r\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # Update parameters and take a step using the computed gradient.\r\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\r\n",
        "        # modified based on their gradients, the learning rate, etc.\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # Update the learning rate.\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "    # Calculate the average loss over all of the batches.\r\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \r\n",
        "    \r\n",
        "    # Measure how long this epoch took.\r\n",
        "    training_time = format_time(time.time() - t0)\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "    # After the completion of each training epoch, measure our performance on\r\n",
        "    # our validation set.\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\r\n",
        "    # during evaluation.\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # Tracking variables \r\n",
        "    total_eval_accuracy = 0\r\n",
        "    total_eval_loss = 0\r\n",
        "    nb_eval_steps = 0\r\n",
        "\r\n",
        "    # Evaluate data for one epoch\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        \r\n",
        "        # Unpack this training batch from our dataloader. \r\n",
        "        #\r\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \r\n",
        "        # the `to` method.\r\n",
        "        #\r\n",
        "        # `batch` contains three pytorch tensors:\r\n",
        "        #   [0]: input ids \r\n",
        "        #   [1]: attention masks\r\n",
        "        #   [2]: labels \r\n",
        "        b_input_ids = batch[0].to(device)\r\n",
        "        b_input_mask = batch[1].to(device)\r\n",
        "        b_labels = batch[2].to(device)\r\n",
        "        \r\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\r\n",
        "        # the forward pass, since this is only needed for backprop (training).\r\n",
        "        with torch.no_grad():        \r\n",
        "\r\n",
        "            # Forward pass, calculate logit predictions.\r\n",
        "            # token_type_ids is the same as the \"segment ids\", which \r\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\r\n",
        "            # The documentation for this `model` function is here: \r\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\r\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\r\n",
        "            # values prior to applying an activation function like the softmax.\r\n",
        "            (loss, logits) = model(b_input_ids, \r\n",
        "                                   token_type_ids=None, \r\n",
        "                                   attention_mask=b_input_mask,\r\n",
        "                                   labels=b_labels)\r\n",
        "            \r\n",
        "        # Accumulate the validation loss.\r\n",
        "        total_eval_loss += loss.item()\r\n",
        "\r\n",
        "        # Move logits and labels to CPU\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "        # Calculate the accuracy for this batch of test sentences, and\r\n",
        "        # accumulate it over all batches.\r\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\r\n",
        "        \r\n",
        "\r\n",
        "    # Report the final accuracy for this validation run.\r\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\r\n",
        "\r\n",
        "    # Calculate the average loss over all of the batches.\r\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\r\n",
        "    \r\n",
        "    # Measure how long the validation run took.\r\n",
        "    validation_time = format_time(time.time() - t0)\r\n",
        "    \r\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\r\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\r\n",
        "\r\n",
        "    # Record all statistics from this epoch.\r\n",
        "    training_stats.append(\r\n",
        "        {\r\n",
        "            'epoch': epoch_i + 1,\r\n",
        "            'Training Loss': avg_train_loss,\r\n",
        "            'Valid. Loss': avg_val_loss,\r\n",
        "            'Valid. Accur.': avg_val_accuracy,\r\n",
        "            'Training Time': training_time,\r\n",
        "            'Validation Time': validation_time\r\n",
        "        }\r\n",
        "    )\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")\r\n",
        "\r\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    505.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    505.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    505.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    505.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    505.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    505.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    505.    Elapsed: 0:01:47.\n",
            "  Batch   320  of    505.    Elapsed: 0:02:02.\n",
            "  Batch   360  of    505.    Elapsed: 0:02:17.\n",
            "  Batch   400  of    505.    Elapsed: 0:02:33.\n",
            "  Batch   440  of    505.    Elapsed: 0:02:48.\n",
            "  Batch   480  of    505.    Elapsed: 0:03:03.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    505.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    505.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    505.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    505.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    505.    Elapsed: 0:01:16.\n",
            "  Batch   240  of    505.    Elapsed: 0:01:31.\n",
            "  Batch   280  of    505.    Elapsed: 0:01:46.\n",
            "  Batch   320  of    505.    Elapsed: 0:02:01.\n",
            "  Batch   360  of    505.    Elapsed: 0:02:16.\n",
            "  Batch   400  of    505.    Elapsed: 0:02:31.\n",
            "  Batch   440  of    505.    Elapsed: 0:02:46.\n",
            "  Batch   480  of    505.    Elapsed: 0:03:01.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:03:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.22\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    505.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    505.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    505.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    505.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    505.    Elapsed: 0:01:15.\n",
            "  Batch   240  of    505.    Elapsed: 0:01:31.\n",
            "  Batch   280  of    505.    Elapsed: 0:01:46.\n",
            "  Batch   320  of    505.    Elapsed: 0:02:01.\n",
            "  Batch   360  of    505.    Elapsed: 0:02:16.\n",
            "  Batch   400  of    505.    Elapsed: 0:02:31.\n",
            "  Batch   440  of    505.    Elapsed: 0:02:46.\n",
            "  Batch   480  of    505.    Elapsed: 0:03:01.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:03:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.24\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    505.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    505.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    505.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    505.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    505.    Elapsed: 0:01:15.\n",
            "  Batch   240  of    505.    Elapsed: 0:01:30.\n",
            "  Batch   280  of    505.    Elapsed: 0:01:45.\n",
            "  Batch   320  of    505.    Elapsed: 0:02:01.\n",
            "  Batch   360  of    505.    Elapsed: 0:02:16.\n",
            "  Batch   400  of    505.    Elapsed: 0:02:31.\n",
            "  Batch   440  of    505.    Elapsed: 0:02:46.\n",
            "  Batch   480  of    505.    Elapsed: 0:03:01.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:03:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.25\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:13:13 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Lds_mCR513Ld",
        "outputId": "489595fc-d26d-4235-d72b-ff4757ce5803"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Display floats with two decimal places.\r\n",
        "pd.set_option('precision', 2)\r\n",
        "\r\n",
        "# Create a DataFrame from our training statistics.\r\n",
        "df_stats = pd.DataFrame(data=training_stats)\r\n",
        "\r\n",
        "# Use the 'epoch' as the row index.\r\n",
        "df_stats = df_stats.set_index('epoch')\r\n",
        "\r\n",
        "# A hack to force the column headers to wrap.\r\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\r\n",
        "\r\n",
        "# Display the table.\r\n",
        "df_stats"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:03:12</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.09</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:03:11</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:03:10</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:03:10</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.18         0.17           0.95       0:03:12         0:00:07\n",
              "2               0.09         0.22           0.95       0:03:11         0:00:07\n",
              "3               0.05         0.24           0.95       0:03:10         0:00:07\n",
              "4               0.03         0.25           0.95       0:03:10         0:00:07"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "4lhqmqL88PGN",
        "outputId": "cc9dc483-7705-4a9b-e40c-60533ec9170e"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "% matplotlib inline\r\n",
        "\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Use plot styling from seaborn.\r\n",
        "sns.set(style='darkgrid')\r\n",
        "\r\n",
        "# Increase the plot size and font size.\r\n",
        "sns.set(font_scale=1.5)\r\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\r\n",
        "\r\n",
        "# Plot the learning curve.\r\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\r\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\r\n",
        "\r\n",
        "# Label the plot.\r\n",
        "plt.title(\"Training & Validation Loss\")\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.legend()\r\n",
        "plt.xticks([1, 2, 3, 4])\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTjc-6Dgd4sW"
      },
      "source": [
        "Testing on SemEval test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTktGH3o-8I3"
      },
      "source": [
        "df_test = df4.append(df3)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM0EMJRm__N_",
        "outputId": "915d7ec8-6667-4e27-b0c4-9a060df4a78c"
      },
      "source": [
        "df_test.info"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                                Sentence  ... Label\n",
              "0     The name given to our cluster, Valhalla, comes...  ...     1\n",
              "1     This as well as kinetic data support the hypot...  ...     1\n",
              "2     Hundreds of thousands in central China are sle...  ...     1\n",
              "3     Dehydration from fluid loss generally is the o...  ...     1\n",
              "4     Fathers, in particular, are often more involve...  ...     1\n",
              "...                                                 ...  ...   ...\n",
              "2712  After seating all the idols, which itself take...  ...     0\n",
              "2713  The minister attributed the slow production of...  ...     0\n",
              "2714  The umbrella frame is provided with a movable ...  ...     0\n",
              "2715  Manos: The Hands of Fate is a low-budget horro...  ...     0\n",
              "2716  A few days before the service, Tom Burris had ...  ...     0\n",
              "\n",
              "[3266 rows x 3 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aENE39NAWTm"
      },
      "source": [
        "df_test = df_test[df_test['Sentence'].notna()]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-3JCjXIAFqn",
        "outputId": "b0da84bc-9e0d-43a1-f7a9-2a9ca18caafc"
      },
      "source": [
        "# Report the number of sentences.\r\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\r\n",
        "\r\n",
        "# Create sentence and label lists\r\n",
        "sentences = df_test.Sentence.values\r\n",
        "labels = df_test.Label.values\r\n",
        "\r\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\r\n",
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# For every sentence...\r\n",
        "for sent in sentences:\r\n",
        "    # `encode_plus` will:\r\n",
        "    #   (1) Tokenize the sentence.\r\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\r\n",
        "    #   (3) Append the `[SEP]` token to the end.\r\n",
        "    #   (4) Map tokens to their IDs.\r\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\r\n",
        "    #   (6) Create attention masks for [PAD] tokens.\r\n",
        "    encoded_dict = tokenizer.encode_plus(\r\n",
        "                        sent,                      # Sentence to encode.\r\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\r\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\r\n",
        "                        pad_to_max_length = True,\r\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\r\n",
        "                        truncation=True\r\n",
        "                   )\r\n",
        "    \r\n",
        "    # Add the encoded sentence to the list.    \r\n",
        "    input_ids.append(encoded_dict['input_ids'])\r\n",
        "    \r\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\r\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Set the batch size.  \r\n",
        "batch_size = 16  \r\n",
        "\r\n",
        "# Create the DataLoader.\r\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "prediction_sampler = SequentialSampler(prediction_data)\r\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 8,000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVMbLjSjAUEn",
        "outputId": "312fbc8a-e488-44c6-dc08-b134875b0155"
      },
      "source": [
        "# Prediction on test set\r\n",
        "\r\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\r\n",
        "\r\n",
        "# Put model in evaluation mode\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# Tracking variables \r\n",
        "predictions , true_labels = [], []\r\n",
        "\r\n",
        "# Predict \r\n",
        "for batch in prediction_dataloader:\r\n",
        "  # Add batch to GPU\r\n",
        "  batch = tuple(t.to(device) for t in batch)\r\n",
        "  \r\n",
        "  # Unpack the inputs from our dataloader\r\n",
        "  b_input_ids, b_input_mask, b_labels = batch\r\n",
        "  \r\n",
        "  # Telling the model not to compute or store gradients, saving memory and \r\n",
        "  # speeding up prediction\r\n",
        "  with torch.no_grad():\r\n",
        "      # Forward pass, calculate logit predictions\r\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \r\n",
        "                      attention_mask=b_input_mask)\r\n",
        "\r\n",
        "  logits = outputs[0]\r\n",
        "\r\n",
        "  # Move logits and labels to CPU\r\n",
        "  logits = logits.detach().cpu().numpy()\r\n",
        "  label_ids = b_labels.to('cpu').numpy()\r\n",
        "  \r\n",
        "  # Store predictions and true labels\r\n",
        "  predictions.append(logits)\r\n",
        "  true_labels.append(label_ids)\r\n",
        "\r\n",
        "print('    DONE.')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,264 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCKBAux3Ao5e",
        "outputId": "9d5f529c-6f5b-408e-a0c4-2c6a45de9fa4"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\r\n",
        "# Combine the results across all batches. \r\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\r\n",
        "\r\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\r\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\r\n",
        "\r\n",
        "# Combine the correct labels for each batch into a single list.\r\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\r\n",
        "\r\n",
        "\r\n",
        "matrix = confusion_matrix(flat_true_labels,flat_predictions)\r\n",
        "print(matrix)\r\n",
        "score = accuracy_score(flat_true_labels,flat_predictions)\r\n",
        "print(score)\r\n",
        "report = classification_report(flat_true_labels, flat_predictions)\r\n",
        "print(report)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2782   74]\n",
            " [  58  350]]\n",
            "0.9595588235294118\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      2856\n",
            "           1       0.83      0.86      0.84       408\n",
            "\n",
            "    accuracy                           0.96      3264\n",
            "   macro avg       0.90      0.92      0.91      3264\n",
            "weighted avg       0.96      0.96      0.96      3264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXWCSeOJRymC"
      },
      "source": [
        "Testing on Climate Val Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpWcMjkOTPM-"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/climateMind')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWr8BCriBRkm"
      },
      "source": [
        "df_test = pd.read_csv('Validation Dataset- Cause_Effects - Classifier (1).csv')"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwGGt2wqT-dU",
        "outputId": "09b5e4d6-031a-40d5-d457-2393a3c54ec5"
      },
      "source": [
        "df_test['Sentence(s)']"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Record downpours in Tennessee provoked a state...\n",
              "1      In California, heavy precipitation damaged tho...\n",
              "2      Extreme rain events have devastated communitie...\n",
              "3      More than 70% of the planet’s surface is water...\n",
              "4      Every 1°F rise also allows the atmosphere to h...\n",
              "                             ...                        \n",
              "215    Climate scientists have correlated the growing...\n",
              "216    By mid-century, the annual area burned in the ...\n",
              "217    Wildfire season can spark anytime throughout t...\n",
              "218                            Can rain cause more fire?\n",
              "219                         Wet vegetation doesn’t burn.\n",
              "Name: Sentence(s), Length: 220, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK0V18tfUBa1",
        "outputId": "c55a3728-e480-4349-a54e-a0285bb08d0f"
      },
      "source": [
        "df_test['Nikita_has_cause_effect']"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "215    0\n",
              "216    0\n",
              "217    0\n",
              "218    0\n",
              "219    0\n",
              "Name: Nikita_has_cause_effect, Length: 220, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq7lgP0hUuW8",
        "outputId": "69a64de2-0c33-454c-c45b-d16e42de0cb9"
      },
      "source": [
        "for x in range(0, len(df_test)):\r\n",
        "  df_test.iloc[x]['Nikita_has_cause_effect'] = (int)(df_test.iloc[x]['Nikita_has_cause_effect'])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "TLUSyWwbVLHc",
        "outputId": "18e6e5a1-5372-44ee-de1f-6c1a3f6e38ad"
      },
      "source": [
        "df_test.sample(10)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original curator</th>\n",
              "      <th>keep</th>\n",
              "      <th>Sentence(s)</th>\n",
              "      <th>if edge, edge type (causes or inhibits/inhibited by) ?</th>\n",
              "      <th>Nikita_has_cause_effect</th>\n",
              "      <th>Shweta_has_cause_effect</th>\n",
              "      <th>key word that indicates edge type</th>\n",
              "      <th>if edge, node(s) 1 [start node(s)]</th>\n",
              "      <th>if edge, node(s) 2 [end node(s)]</th>\n",
              "      <th>Easy / Hard Label</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>Nikita</td>\n",
              "      <td>yes?</td>\n",
              "      <td>Earth’s warming climate is forecasted to make ...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>warming climate</td>\n",
              "      <td>global precipitation patterns more extreme</td>\n",
              "      <td>NaN</td>\n",
              "      <td>warming climate leads to more extreme weather ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Shweta</td>\n",
              "      <td>no</td>\n",
              "      <td>Western Washington, also deemed to be at risk ...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>heavy snow packs and rains</td>\n",
              "      <td>unusual number of fires</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Nikita</td>\n",
              "      <td>yes</td>\n",
              "      <td>Insurance in fire-prone areas is getting more ...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fire-prone areas</td>\n",
              "      <td>expensive Insurance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>Kameron</td>\n",
              "      <td>yes</td>\n",
              "      <td>Westerling identified a clear link between cha...</td>\n",
              "      <td>associates with</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>clear link between</td>\n",
              "      <td>changes in temperature</td>\n",
              "      <td>changes in length of fire season</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Kameron</td>\n",
              "      <td>yes</td>\n",
              "      <td>Yet high temperatures and low rain and snowfal...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>driver of</td>\n",
              "      <td>[increase in] high temperatures</td>\n",
              "      <td>[increase in] intense forest fires</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Sampath</td>\n",
              "      <td>yes</td>\n",
              "      <td>For instance, rising average temperatures are ...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>leading to</td>\n",
              "      <td>rising average temperatures</td>\n",
              "      <td>longer ragweed pollen season</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Nikita</td>\n",
              "      <td>no</td>\n",
              "      <td>He and his team examined soil moisture data se...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>greenhouse gas emissions</td>\n",
              "      <td>risk of a megadrought</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>new_sampled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Many military bases along the US East Coast an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Nikita</td>\n",
              "      <td>yes</td>\n",
              "      <td>Wildfire smoke has also been linked to longer-...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wildfire smoke</td>\n",
              "      <td>lower birth weight for babies</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>Nikita</td>\n",
              "      <td>?</td>\n",
              "      <td>With climate change raising the risk of hot an...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>climate change</td>\n",
              "      <td>risk of hot and dry weather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no explicit mention of the cause relationship</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    original curator  ... Unnamed: 11\n",
              "132           Nikita  ...         NaN\n",
              "148           Shweta  ...         NaN\n",
              "93            Nikita  ...         NaN\n",
              "180          Kameron  ...         NaN\n",
              "15           Kameron  ...         NaN\n",
              "115          Sampath  ...         NaN\n",
              "172           Nikita  ...         NaN\n",
              "209      new_sampled  ...         NaN\n",
              "75            Nikita  ...         NaN\n",
              "142           Nikita  ...         NaN\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "760AqCwya6Ni"
      },
      "source": [
        "df_test.columns = ['original curator', 'keep', 'Sentence',\r\n",
        "       'if edge, edge type (causes or inhibits/inhibited by) ?',\r\n",
        "       'Nikita_has_cause_effect', 'Shweta_has_cause_effect',\r\n",
        "       'key word that indicates edge type',\r\n",
        "       'if edge, node(s) 1 [start node(s)]',\r\n",
        "       'if edge, node(s) 2 [end node(s)]', 'Easy / Hard Label', 'Comments',\r\n",
        "       'Unnamed: 11']"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXKsOKYjZLdb",
        "outputId": "17a20623-0fba-431b-aa72-b0e4c46141e8"
      },
      "source": [
        "df_test.Sentence.values"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Record downpours in Tennessee provoked a state of emergency and led to mudslides.',\n",
              "       'In California, heavy precipitation damaged thousands of buildings. ',\n",
              "       'Extreme rain events have devastated communities around the nation — and the frequency and severity of such events are expected to worsen in a warming world.',\n",
              "       'More than 70% of the planet’s surface is water, and as the world warms, more water evaporates from oceans, lakes, and soils.',\n",
              "       'Every 1°F rise also allows the atmosphere to hold 4% more water vapor.',\n",
              "       'In most areas, rainfall extremes have intensified as the climate has warmed.',\n",
              "       'So when weather patterns lead to heavy rain, there is even more moisture available for stronger downpours, increasing the risk and severity of flooding.',\n",
              "       'As the climate warms, these stronger storms can intensify flooding.',\n",
              "       'Finally, most cities have recently observed more storms with an inch of rain or more, causing threats of flooding to spike upward.',\n",
              "       'There are many different factors that contribute to forest fires in a given year, including how many fires are ignited (arson, lightning strikes, downed power lines, malfunctioning equipment, etc), where they occur, how high temperatures are, how low precipitation has been and wind conditions where fires occur.',\n",
              "       'They found that, while land-use history and “fuel-loading” – the amount of accumulated burnable vegetation – were important factors for specific forest areas, “the broad-scale increase in wildfire frequency across the western US has been driven primarily by sensitivity of fire regimes to recent changes in climate over a relatively large area”.',\n",
              "       'Most of the area burned today is in the western US, where dryer conditions tend to allow for large, quickly-spreading wildfires.',\n",
              "       'I think it is shown without any room for reasonable doubt that climate is warming and becoming more variable because of human activity.',\n",
              "       'Because precipitation is more variable in western US and temperatures are increasing, you know that wildfires will be amped up because of climate change.',\n",
              "       'While climate models agree that temperatures have increased in the western US due to human activity, the human role in changes in rain and snow over that period is less clear-cut and varies greatly between models.',\n",
              "       'Yet high temperatures and low rain and snowfall are not the only driver of intense forest fires.',\n",
              "       'Fuel-loading and the damages resulting from wildfires have also been magnified by an increase in the number of people living in remote, forested areas in recent decades.',\n",
              "       'Larger populations increase the political pressure to limit controlled burns and other preventative measures to reduce fuel load.',\n",
              "       'The figure below, taken from their 2014 paper, shows the role that changes in human activity – mainly burning land to convert forest areas to agriculture – as well as climate change and CO2 fertilisation and increased nitrogen deposition – increased atmospheric CO2 and nitrogen pollution that both help fertilize plants and increase growth of flammable vegetation – have played in the area burned by wildfires in different regions of the world.',\n",
              "       'The data, to be published in full next month, shows the extra strain that poor air quality is putting on already stretched NHS emergency resources',\n",
              "       'Simon Stevens, the chief executive of NHS England, said: “These new figures show air pollution is now causing thousands of strokes, cardiac arrests and asthma attacks, so it’s clear that the climate emergency is in fact also a health emergency',\n",
              "       'Jenny Bates, an air pollution campaigner at Friends of the Earth, said: “Many people may not realise how dangerous air pollution at high levels can be, and that it can trigger heart attacks, strokes and asthma attacks as well as having long-term health effects.',\n",
              "       'Bates said clean air zones were needed, but also measures to cut all traffic “because all vehicles produce deadly fine particle air pollution from brake and tyre wear',\n",
              "       'Climate change contributes to more and bigger wildfires in a variety of ways.\\n',\n",
              "       'The rise in average global temperatures has led to higher spring and summer temperatures, and importantly an earlier onset of spring',\n",
              "       'This pattern has led to a rapid melting of spring snowpack, causing soils to dry out earlier and remain dry longer.',\n",
              "       'Warming temperatures have allowed populations of mountain pine beetles to explode at elevations and latitudes where winters were historically cold enough to limit their numbers',\n",
              "       'As wildfires grow in frequency, intensity, and the amount of area burned, they pose serious health risks.\\n\\n',\n",
              "       'Smoke from wildfires contains volatile and semi-volatile organic compounds and nitrogen oxides that form ozone and organic particulates and other toxic pollutants – all of which can be dangerous and even deadly for sensitive populations',\n",
              "       'Wildfires also impact climate change because they emit massive amounts of carbon dioxide and other pollutants that can affect regional and even global climate.',\n",
              "       'While wildfires can be natural drivers of rejuvenation in forest landscapes, the frequency and intensity of fires as the global climate warms can sterilize soils and destroy a forest’s ability to recover.',\n",
              "       'To limit the damage from such destructive fires, many forest managers say it’s critical to thin dying and dead timber from forests',\n",
              "       'The rain and snow created perfect growing conditions for shrubs, grasses and young trees — highly flammable material that, along with dead wood from previous years, becomes a tinderbox during the dry summer season.',\n",
              "       'Fire has always been a fact of life in the West, but the length and severity of fire season are increasing because of decades of fire suppression that caused fuel to build up on the forest floor, and ever-rising temperatures that are drying out our wildlands.',\n",
              "       'As we implement these programs, we must put a premium on increasing community resilience and preparedness in high-risk areas — by clearing small trees and fuel and building literal fire breaks to keep people and property safer.',\n",
              "       'Volatility in conditions, from rains to extreme drought, can prime the land for fire',\n",
              "       'Wildfires can spread easily during periods of dry and warm conditions',\n",
              "       'If the dry conditions persist, a drought can develop, leading to conditions favorable for wildfires as all the excess dried-out vegetation provides ample fuel for the fires.',\n",
              "       'Wildfires will ignite very easily under such dry conditions and can spread quickly',\n",
              "       'Lightning can be a good starter of wildfires, especially under such dry conditions',\n",
              "       'Careless use of camping or trash-burning fires and even tossed cigarettes can also start fires',\n",
              "       'In these areas, burn bans will be put into effect in an effort to stop the wildfires from developing and easily spreading.',\n",
              "       'In many areas across the Southeast US, controlled burning efforts are used as a precaution to try to contain wildfires if they do happen to start up randomly',\n",
              "       'With controlled burning efforts, the short brush in the forest is burned up to eliminate the fuel source for the fires',\n",
              "       'Though El Niño conditions vary in each episode, the increase in the average amount of rainfall allows for underbrush to grow in forests',\n",
              "       'Communities in the Southeast are often happy to welcome the warmer weather during the winter season because frosts and freezes will be less likely, although the warmer weather can cause problems in the Midwest for crops like winter wheat, due to more frequent freeze-thaw cycles in these years in the colder climates.',\n",
              "       'This wet and warm weather allowed plants and underbrush to grow in the forests',\n",
              "       'The hot and dry conditions led to the development of large numbers of wildfires across Florida’s coast.',\n",
              "       'This led to the drought across the state of Florida with the below average amount of rainfall which continued throughout the rest of the year, damaging many hundreds of acres of farmland and forests. ',\n",
              "       'Wildfires can start easily under warm and dry conditions with low relative humidity',\n",
              "       'Wildfires get easily out of control in California because of the type of trees in the forest accompanied by conditions of low relative humidity and warm air',\n",
              "       'Strong winds also help with the spread of wildfires throughout California',\n",
              "       'These California fires damage a lot of farmland every year as well as forests that are a natural habitat for animals',\n",
              "       'Increased forest fire activity across the western United States in recent decades has contributed to widespread forest mortality, carbon emissions, periods of degraded air quality, and substantial fire suppression expenditures.',\n",
              "       'Although numerous factors aided the recent rise in fire activity, observed warming and drying have significantly increased fire-season fuel aridity, fostering a more favorable fire environment across forested systems',\n",
              "       'We demonstrate that human-caused climate change caused over half of the documented increases in fuel aridity since the 1970s and doubled the cumulative forest fire area since 1984.',\n",
              "       'Anthropogenic increases in temperature and vapor pressure deficit significantly enhanced fuel aridity across western US forests over the past several decades and, during 2000–2015, contributed to 75% more forested area experiencing high (>1 σ) fire-season fuel aridity and an average of nine additional days per year of high fire potential.',\n",
              "       'Our analysis shows that ACC accounts for ∼54% of the increase in fire-weather season length in the all-metric mean (15–79% for individual metrics).',\n",
              "       'Since the 1970s, human-caused increases in temperature and vapor pressure deficit have enhanced fuel aridity across western continental US forests, accounting for approximately over half of the observed increases in fuel aridity during this period.',\n",
              "       'The growing ACC influence on fuel aridity is projected to increasingly promote wildfire potential across western US forests in the coming decades and pose threats to ecosystems, the carbon budget, human health, and fire suppression budgets (13, 48) that will collectively encourage the development of fire-resilient landscapes',\n",
              "       'Wildfires are a major driver of greenhouse gas emissions and are also responsible for 5-8% of the 3.3 million annual premature deaths from poor air quality, research suggests.',\n",
              "       'Fires in Indonesia have been worsened by the practice of draining peatlands.',\n",
              "       'When temperatures are warmer than average, rates of evaporation increase, causing moisture to be drawn out from plants on the land',\n",
              "       'But if you have a huge drought or heatwave, a lot of that vegetation will be very dry and, therefore, it will become fuel.',\n",
              "       'We found that climate change made the bushfires at least 30% more likely – and that is a conservative estimate.',\n",
              "       'As well as making fires more severe, warming temperatures are also making fire seasons longer in some regions, explains Dr Megan Kirchmeier-Young, a researcher of climate extremes at the Government of Canada.',\n",
              "       'This creates “fire breaks” in the landscape, which can prevent fires from quickly spreading over large areas of wildland.',\n",
              "       'A study published in Science in 2006 found that the accumulation of trees – also known as “fuel loading” – and human-caused climate change are both important factors in increased fire risk across the western US. Lake says',\n",
              "       'Fires in the country have been exacerbated further by the practice of peatland draining.',\n",
              "       'Climate change will continue to drive temperature rise and more unpredictable rainfall in many parts of the world',\n",
              "       'But outdated forest management practices and climate change — which brings hotter, drier conditions — have provided the kindling for infernos of such immense scale. ',\n",
              "       'New growth, including more flammable brush and grasses, could fuel fires and put homes and lives at risk again, he said. ',\n",
              "       'As the climate has warmed, fire season, which traditionally peaks in late summer and into the fall, has been expanding — sometimes starting as early as the spring, and lasting into late fall.',\n",
              "       'Fires have become more destructive over time, especially as people have moved further into fire-prone areas.',\n",
              "       'Breathing in high concentrations of particulate pollution can worsen asthma and other respiratory problems in the short term, and can even lead to strokes or heart attacks.',\n",
              "       'Wildfire smoke has also been linked to longer-term consequences, like lower birth weight for babies and impaired lung function in adults. ',\n",
              "       'Increasing heat, changing rain and snow patterns, shifts in plant communities, and other climate-related changes have vastly increased the likelihood that fires will start more often and burn more intensely and widely than they have in the past.',\n",
              "       'Other factors also hike fire risk, like forest management decisions that have allowed for the buildup of vast amounts of vegetation that can quickly turn into fuel, as well as more problematic issues like the slow creep of houses and other infrastructure into risky areas.',\n",
              "       'Human-caused ignitions are clearly a major part of the risk: A study published in September, on which Balch was a co-author, found that humans were responsible for 97 percent of the ignitions that caused fires that then threatened homes in the wildland-urban interface, between 1992 and 2015',\n",
              "       'The planet has heated up nearly continuously since the start of the Industrial Revolution in the late 1800s, when humans started burning massive quantities of fossil fuels, releasing carbon dioxide that traps excess heat in the atmosphere',\n",
              "       'Scientists can measure this \"vapor pressure deficit\"—the difference between how much water the air holds and how much it could hold. If that deficit is cranked up for a long time, soils and vegetation will parch.',\n",
              "       'Intense, record-breaking heat waves like the ones that encompassed the West during August and early September likely caused major crisping of burnable material, as the regional vapor pressure deficit and associated drought climbed to record levels.',\n",
              "       'When excess heat stays in place for months or longer, the wildfire risk rises even further.',\n",
              "       'An early, warm spring can jump-start a summer drought by extending the season of heat and growth, increasing the amount of water vapor that is shed by plant leaves or that evaporates directly from soil. ',\n",
              "       'When there’s no moisture left to evaporate, the soil or vegetation, dead and alive, absorbs that heat instead—feeding back into the drying-out process that increases fire risk.',\n",
              "       'Since the 1970s, a recent study found, human-caused climate change caused more than half of the drying-out of burnable materials and consequent fire risk.',\n",
              "       'Higher autumn temperatures and less precipitation—in particular, a growing delay in the onset of winter rains, which usually puts an end to the fire season in California—have led to a 20 percent increase in the number of autumn days ripe for burning',\n",
              "       \"California's fires are disruptive long after they are put out, displacing homeowners and even entire communities for months or years\",\n",
              "       \"Weakened by a prolonged drought, which scientists link to climate change, California's ubiquitous pines and oaks are vulnerable to insect infestation and disease\",\n",
              "       'Moreover, as more trees die, another weapon to combat climate change is lost: the prodigious ability of healthy trees to absorb carbon from the atmosphere. ',\n",
              "       'Fast-growing and opportunistic non-native plants rush in after fires, with the potential to wholly supplant native species.',\n",
              "       'Invasive grasses and weeds often burn more readily, fanning hotter and more frequent fires.',\n",
              "       'When fires burn in uninhabited wildlands, their corrosive effects can be carried hundreds of miles by the wind, causing stinging eyes, burning throats and severe coughing.',\n",
              "       'Insurance in fire-prone areas is getting more expensive.',\n",
              "       'Droughts can create ideal conditions for wildfires',\n",
              "       'Lack of rain and low humidity dry out trees and vegetation, providing fuel.',\n",
              "       'So in the short term, more droughts probably mean more fire as the vegetation dries out,',\n",
              "       '“Once we change the climatology and get drier and drier fuels, we should expect more intense fires and higher fire severity,” said Adam Kochanski, an atmospheric scientist at the University of Utah, referring to the size and impact of the fires.',\n",
              "       'Dry conditions may prevent new seeds from germinating in the burned areas.',\n",
              "       'Vegetation loss can lead to erosion and sediment blocking waterways, and firefighting chemicals may contaminate water sources.',\n",
              "       'It creates this vicious cycle where snow melts earlier due to climate change, which extends the summer drought period where the soil dries out, and when the fuels dry out, you get these big fires',\n",
              "       'As climate change progresses, temperatures will continue to rise, meaning greater rates of evapotranspiration that will cause plants to dry out faster',\n",
              "       '“Global warming is expected to cause extreme weather events, which may, in turn, result in large day-to-day fluctuations in temperature,” said Hedvig Andersson, a cardiology researcher at the University of Michigan. “Our study suggests that such fluctuations in outdoor temperature could potentially lead to an increased number of heart attacks and affect global cardiac health in the future.”',\n",
              "       'Changes of more than 25 degrees Celsius, or 45 degrees Fahrenheit, were linked to a greater increase in heart attack rates compared to a smaller increase with temperature swings of 10 to 25 degrees Celsius, or 18–45 degrees Fahrenheit, according to the researchers.',\n",
              "       'A study in the British Medical Journal found that each 1C temperature drop on a single day in the UK is linked to 200 extra heart attacks.',\n",
              "       'They found that a 1C reduction in average daily temperature was linked with a cumulative 2% increase in risk of heart attack for 28 days, even in the summer.',\n",
              "       'Both excessively low and high temperatures affect cardiac diseases [2], and climate change can therefore affect local patterns of heart disease in several ways.',\n",
              "       '\"Our study suggests that greater consideration should be given to high temperatures as a potential trigger for heart attacks -- especially in view of climate change,\"',\n",
              "       'Analyses of daily death rates have shown that both low and high temperatures are associated with increases in cardiovascular disease mortality.',\n",
              "       'Many states were affected by extreme drought. Drought conditions persisted in the Four Corners region of the Southwest, causing damage to crops.',\n",
              "       'It found that in certain years and certain contexts, warming-related drought sparked conflicts that sent refugees abroad.',\n",
              "       'She stressed that climate change may also contribute to low agricultural yields and gross domestic product — conditions that might set the stage for conflict or compel people to leave a country',\n",
              "       'the violence was a consequence of the drought',\n",
              "       'claiming that each rise in temperature or extreme rainfall by one standard variation increased the frequency of interpersonal violence by 4% and intergroup conflict by 14%.',\n",
              "       'by increasing the frequency and intensity of extreme weather events, including floods and droughts, it makes conflict likelier than it would otherwise be',\n",
              "       'For instance, rising average temperatures are leading to a longer ragweed pollen season, as you can see here',\n",
              "       'A 2019 paper published in The Lancet Planetary Health journal found that airborne pollen counts have increased around the world as average temperatures climbed',\n",
              "       'the change in carbon dioxide concentrations from a preindustrial level of 280 parts per million to today’s concentrations of more than 400 ppm has led to a corresponding doubling in pollen production per plant of ragweed.',\n",
              "       'It turns out that higher carbon dioxide concentrations encourage plants to produce more pollen.',\n",
              "       'These findings indicate that air pollutants are significantly associated with ischemic stroke mortality, which suggests an acute pathogenetic process in the cerebrovascular system induced by air pollution.',\n",
              "       'After months of drying in the longer periods of higher temperatures, stressed forests have become more susceptible to infestations by bark beetles and other insects that thrive in warmer temperatures',\n",
              "       'Throughout the western United States and Canada, bark beetles have killed off hundreds of millions of trees and devastated forestlands, turning them into kindling for catastrophic wildfires',\n",
              "       'Meanwhile, the West Coast of the U.S. is particularly susceptible to a kind of weather whiplash – wet winters fueled by atmospheric river storms originating in the Eastern Pacific, followed by parched summers that dry out spring vegetation and transform it into kindling for wildfires in the fall.',\n",
              "       'Wildfires can occur during drought conditions when the land and vegetation have dried out.',\n",
              "       'There’s too much fuel loading and it’s now too warm, the ability of ignition is greater with both lightning and human-set fires, and now we have these much larger and more extensive fires',\n",
              "       'Many fires that erupted in California in August were sparked by lightning strikes, including the August Complex, which has become the state’s largest. ',\n",
              "       'Oregon hospitals reported a 10 percent increase in emergency room visits for breathing problems during this month’s fires',\n",
              "       'More recent blazes feasted on vegetation that has been sucked of moisture by persistent drought',\n",
              "       'decaying forests continue to emit harmful pollutants.',\n",
              "       \"And the damage doesn't cease once flames are snuffed out\",\n",
              "       \"When fires rage in California's mountains, the system that stores and cleans water, feeds streams and rivers, supports fish and other wildlife and literally holds the hillsides together burns up\",\n",
              "       'Areas that face increasingly severe droughts will also be at risk for more and larger fires',\n",
              "       'Earth’s warming climate is forecasted to make global precipitation patterns more extreme:',\n",
              "       'We could also see an increased variability in rainfall, meaning that rain could come in short intense bursts followed by long periods of dryness. soakings during our wet season, recovery from dry periods is more difficult. ',\n",
              "       'Overall, the results showed the risk of a heart attack increased by about 5 percent for every five-degree Celsius jump in temperature differential',\n",
              "       'In September 2013, Boulder, Colorado, received almost a year’s worth of rainfall (17 inches) in four days. The resulting flooding destroyed homes, shut down thousands of oil and gas wells, and damaged crops.',\n",
              "       'And then if dry conditions follow, you’ve got the perfect setting for fire — dry fuel, and lots of it.  ',\n",
              "       'We need to quickly draw down emissions to avoid more catastrophic impacts, and to prioritize measures that reduce our vulnerability to the fires that will continue to occur.',\n",
              "       'Drought conditions sometimes develop after a period of above average amounts of rainfall over an extended area.',\n",
              "       'The complex interactions between fire, climate, and vegetation are one of the more interesting and challenging aspects of understanding how fire is changing on our landscape in response to climatic change.',\n",
              "       'Local fires can be seen in the United States almost every year when the lands start to dry out, particularly in Florida or California in the middle of spring',\n",
              "       'Under drought conditions, not enough precipitation falls to relieve the land from drought and wildfires get out of hand',\n",
              "       'With climate change raising the risk of hot and dry weather in many parts of the world, it may seem prudent to assume that the global area burned by wildfires each year is increasing.',\n",
              "       'With less wild savannah left, sub-Saharan Africa has seen a decline in the number of large wildfires, says Santin.\\n\\n',\n",
              "       'The authors of the Science paper also attribute decreases in burnt area to the conversion of savannah to agricultural land.',\n",
              "       'Much of the recent research on air pollution has focused on the lifelong effects of chronic exposure, including cognitive decline, stunted growth in children and premature death. ',\n",
              "       'The absence of significantly increased powers for local leaders, together with a lack of reference to the need for adequate funding, are the big holes in the bill that will hold action back.',\n",
              "       'Meanwhile, in arid Arizona, heavier-than-normal rains since last fall recently prompted fire officials to issue warnings to people in or near wildland areas prone to fire.',\n",
              "       'Western Washington, also deemed to be at risk this year after heavy snow packs and rains, has already logged an unusual number of fires',\n",
              "       'But then in 2005 rains came and led to a burst of vegetation growth, and sure enough, large fires followed',\n",
              "       'By 2005, rains moistened the forest, helping to protect it from fire.  ',\n",
              "       'These new plants and shallow-rooted trees are the first to start to wilt when dry conditions begin.',\n",
              "       'Many regions experience distinct wildfire seasons, driven by rainy and dry periods and human practices, such as agricultural burning',\n",
              "       'The fires have also wiped out populations of endangered species, including half of Washington’s pygmy rabbit population, according to the New York Times',\n",
              "       'In 2015, Indonesia’s wildfires spiked, causing greenhouse gas release on the same scale as Brazil’s total annual emissions.',\n",
              "       'In the Attica region of Greece, wildfires ripped across large swathes of dry land at lightning speed, causing people to rush to nearby beaches and into the sea.',\n",
              "       'We’ve seen longer fire seasons, which has also affected plant phenology, and we have extended periods of drought.',\n",
              "       'This year, Science Brief – a UK-based web platform run by a team of scientists – released a review of 73 scientific studies finding that climate change is increasing the risk of wildfires at a global level.',\n",
              "       'The review found strong evidence that climate change is making the weather conditions needed for wildfires more likely',\n",
              "       'For example, a study published in 2020 found that, in California, “climate change will further amplify the number of days with extreme fire weather by the end of this century”. ',\n",
              "       'In Australia, days with fire weather akin to that seen during the 2019-2020 bushfires could become at least four times more likely under 2C of global warming, according to Otto’s recent analysis.',\n",
              "       'For future scenarios, global burnt area will continue to decline under a moderate emissions scenario',\n",
              "       'As wind fueled many of the fires in the last month, it also spread a thick blanket of smoke and soot across the region.',\n",
              "       'Climate change has inexorably stacked the deck in favor of bigger and more intense fires across the American West over the past few decades, science has incontrovertibly shown',\n",
              "       'Short-term drought events or heat waves are really impactful for drying those out.',\n",
              "       'So climate change has increased fire risk in both direct and indirect ways',\n",
              "       'The state has exceeded projected fire suppression costs in seven of the last 10 years.',\n",
              "       \"And rather than waiting to respond to a wildfire, emergency personnel have shifted to pre-positioning strike teams before a fire even starts. It's a strategy that costs more.\",\n",
              "       'The financial toll for homeowners, renters and businesses in the past two fire seasons has topped $10 billion in insured losses each year.',\n",
              "       'A December 2017 survey by the California Department of Insurance found an uptick in renewal complaints in areas designated by Cal Fire as having the greatest risk of wildfire.',\n",
              "       'At the same time, insurance policies of last resort written for brush and wildfire areas have increased from 22,397 policies to 33,898 policies, a 51 percent increase over five years.',\n",
              "       'Fire investigators say PG&E equipment caused a dozen Northern California fires, including the Nuns Fire and Atlas Fire, during a month of hot, dry and windy conditions',\n",
              "       'He and his team examined soil moisture data sets and drought severity indices from 17 different future climate models, and they all predicted that if greenhouse gas emissions continue to increase at their present rate, the risk of a megadrought in the American Southwest could hit 80 percent by the end of the century. ',\n",
              "       'An increase in the risk of acute-onset ischaemic heart disease with increasing temperatures is biologically plausible, given the pathophysiological implications of increased heat exposure.',\n",
              "       'In 2010, almost 20 inches of rain fell in the Nashville, Tennessee, area over three days. Losses in Nashville alone totaled over $1 billion.',\n",
              "       \"According to an analysis performed by insurance company Munich Re, the United States incurred $95 billion in damages caused by natural disasters in 2020, thanks at least in part to climate change's role in producing increasingly common instances of extreme weather events.\",\n",
              "       'Climate change had a hand in the Arab Spring uprising in Tunisia, Libya, Yemen and Syria between 2010 and 2012.',\n",
              "       'Allergies, which are already a major health burden, will become an even larger drain on the economy.',\n",
              "       'Trend data suggest that the prevalence of asthma, including forms of the disease triggered by pollen, mold, and other allergenic substances, is on the rise',\n",
              "       'The recent period of large wildfires in forested areas of the western US has coincided with near-record warm temperatures.',\n",
              "       'Westerling identified a clear link between changes in temperature, length of fire season and areas burned over time.',\n",
              "       'As the figure below shows, there is a strong relationship between temperature (black line) and fire extent (red bars), with warmer years generally having higher fire extent than relatively cooler ones since the early 1980s.',\n",
              "       'A recent 2016 paper in PNAS by Prof John Abatzogloua at the University of Idaho and Prof A Park Williams at Columbia University found an even stronger relationship between forest fire area and fuel aridity – a combination of temperature and precipitation – in the western US.',\n",
              "       'Abatzogloua tells Carbon Brief: “We see a strong relationship between year-to-year variations in how dry fuels are and how much burns in western forests.”',\n",
              "       'He explains that about 75% of year-to-year variations in burned area can be explained by a single climate variable – fuel aridity.',\n",
              "       'Previous studies have found spikes in hospital admissions and GP visits on days of high pollution, but the new data gives precise numbers for nine English cities and shows a clear relationship between heart attacks, strokes and respiratory illnesses and dirty air.',\n",
              "       'Heather Walton, a health expert with the environmental research group at KCL, said the study was intended to provide more detail than others that have tended to concentrate on the effects of air pollution on life expectancy, such as estimates that pollution contributes to 36,000 deaths a year in the UK.',\n",
              "       'As global temperatures rise, wildfires are getting more frequent and intense',\n",
              "       'Climate scientists have correlated the growing incidence and intensity of wildfires with rising global temperatures.',\n",
              "       'The Department for Environment, Food and Rural Affairs said: “We are taking urgent action to improve air quality and tackle pollution so people can live longer healthier lives',\n",
              "       'Last week Europe’s environmental watchdog found that little or no progress had been made across Europe on cutting levels of fine particulate matter, known as PM2.5, which is one of the most dangerous forms of pollution because it can lodge deep in the lungs and penetrate the bloodstream.',\n",
              "       'Each year emergency services see more than 120 additional cardiac arrests, more than 230 additional strokes and nearly 200 more people with asthma requiring hospital treatment on days of high pollution compared with the average on days of lower pollution.',\n",
              "       'By homing in on hospital admissions for cardiac arrests, strokes and asthma, the researchers were able to provide a clearer picture of the acute impacts on people and how emergency services are affected. ',\n",
              "       'Wildfire season can spark anytime throughout the year in arid regions where Mediterranean climates predominate, such as Spain, Portugal, and much of California.',\n",
              "       'Researchers in the United Kingdom have found the strongest link yet between climate change, conflict and migration',\n",
              "       '\"The reality is that climate change is shaping the conversations that they\\'re having in the Security Council now,\" she said.',\n",
              "       'The most obvious cause of their suffering is ideological.',\n",
              "       'We’re seeing increases in both the number of people with allergies and what they’re allergic to',\n",
              "       'Pollen, an allergy trigger for one in five Americans, is surging year after year. ',\n",
              "       'Coupled climate/tropospheric chemistry modeling indicates ozone levels could rise significantly by the end of the century as emissions of precursor pollutants also continue rising',\n",
              "       'Epidemiological studies incorporating time-series analyses have demonstrated an association between short-term exposure to air pollution and increased mortality after adjustment for confounding factors.',\n",
              "       'Relative risks for the pollutant increases were greater for ischemic stroke mortality than for hemorrhagic stroke mortality, except for TSP on the same day.',\n",
              "       'This is a portentous harbinger of global climate change, and an irksome turn of events, as it forced people to switch their clothes, thermostats and ceiling fans from one day to another.',\n",
              "       'As it turns out, such abrupt temperature swings also may be bad for your health.',\n",
              "       'Many of these were sudden cardiac deaths related to heart conditions other than heart attack.',\n",
              "       'Most of the casualties were people in their 70s and 80s, but people who had been taking aspirin long-term appeared to be less vulnerable for some reason. ',\n",
              "       \"In the Shanghai Women's Health Study, cycling for transportation was inversely and independently associated with all-cause mortality.\",\n",
              "       'Analyses of daily death rates have shown that both low and high temperatures are associated with increases in cardiovascular disease mortality',\n",
              "       'Prices and precision vary for these approaches, but the value can be high, especially for high operating cost, high water scarcity regions.',\n",
              "       'Many military bases along the US East Coast and Gulf of Mexico are at risk of permanently losing land to the ocean in the decades ahead.',\n",
              "       'The biggest preventive measure the academy will take is improving the seawall that extends around three-quarters of the yard’s perimeter.',\n",
              "       'Although exposure to sulphur dioxide has been greatly reduced in the developed world through the use of scrubbing equipment in coal-fired power plants and energy sources other than coal combustion, it is a problem in developing countries. ',\n",
              "       'The conflicting results hint at the complexities of climate research, but, since then, the influence of human-caused climate change on extreme weather has become more clear.',\n",
              "       'We’re going to see increases in extreme events, and we need to be prepared.',\n",
              "       'The government has pledged to tackle air pollution in its environment bill, proposals for which were laid out after the Queen’s speech',\n",
              "       'Climate scientists have correlated the growing incidence and intensity of wildfires with rising global temperatures.',\n",
              "       'By mid-century, the annual area burned in the Western U.S., for example, could increase two to six times what it is today, according to the Fourth National Climate Assessment.',\n",
              "       'Wildfire season can spark anytime throughout the year in arid regions where Mediterranean climates predominate, such as Spain, Portugal, and much of California',\n",
              "       'Can rain cause more fire?', 'Wet vegetation doesn’t burn.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fLynoeBaHJu",
        "outputId": "bdc00268-f857-46e1-f233-25139ed00665"
      },
      "source": [
        "df_test.Nikita_has_cause_effect.values"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z88DQ-fcVU_N",
        "outputId": "1d033e7b-be56-41c8-bd1f-fa75ae894b10"
      },
      "source": [
        "# Report the number of sentences.\r\n",
        "print('Number of test sentences: {:,}\\n'.format(df_test.shape[0]))\r\n",
        "\r\n",
        "# Create sentence and label lists\r\n",
        "labels = df_test.Nikita_has_cause_effect.values\r\n",
        "sentences = df_test.Sentence.values\r\n",
        "\r\n",
        "\r\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\r\n",
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# For every sentence...\r\n",
        "for sent in sentences:\r\n",
        "    # `encode_plus` will:\r\n",
        "    #   (1) Tokenize the sentence.\r\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\r\n",
        "    #   (3) Append the `[SEP]` token to the end.\r\n",
        "    #   (4) Map tokens to their IDs.\r\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\r\n",
        "    #   (6) Create attention masks for [PAD] tokens.\r\n",
        "    encoded_dict = tokenizer.encode_plus(\r\n",
        "                        sent,                      # Sentence to encode.\r\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\r\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\r\n",
        "                        pad_to_max_length = True,\r\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\r\n",
        "                        truncation=True\r\n",
        "                   )\r\n",
        "    \r\n",
        "    # Add the encoded sentence to the list.    \r\n",
        "    input_ids.append(encoded_dict['input_ids'])\r\n",
        "    \r\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\r\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Set the batch size.  \r\n",
        "batch_size = 16  \r\n",
        "\r\n",
        "# Create the DataLoader.\r\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "prediction_sampler = SequentialSampler(prediction_data)\r\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 220\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq2T8Xp6YMel",
        "outputId": "75de95ab-ab3d-4aa5-d98c-6572a59a083a"
      },
      "source": [
        "# Prediction on test set\r\n",
        "\r\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\r\n",
        "\r\n",
        "# Put model in evaluation mode\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# Tracking variables \r\n",
        "predictions , true_labels = [], []\r\n",
        "\r\n",
        "# Predict \r\n",
        "for batch in prediction_dataloader:\r\n",
        "  # Add batch to GPU\r\n",
        "  batch = tuple(t.to(device) for t in batch)\r\n",
        "  \r\n",
        "  # Unpack the inputs from our dataloader\r\n",
        "  b_input_ids, b_input_mask, b_labels = batch\r\n",
        "  \r\n",
        "  # Telling the model not to compute or store gradients, saving memory and \r\n",
        "  # speeding up prediction\r\n",
        "  with torch.no_grad():\r\n",
        "      # Forward pass, calculate logit predictions\r\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \r\n",
        "                      attention_mask=b_input_mask)\r\n",
        "\r\n",
        "  logits = outputs[0]\r\n",
        "\r\n",
        "  # Move logits and labels to CPU\r\n",
        "  logits = logits.detach().cpu().numpy()\r\n",
        "  label_ids = b_labels.to('cpu').numpy()\r\n",
        "  \r\n",
        "  # Store predictions and true labels\r\n",
        "  predictions.append(logits)\r\n",
        "  true_labels.append(label_ids)\r\n",
        "\r\n",
        "print('    DONE.')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 220 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amIOdVhWicBP",
        "outputId": "7342162c-7336-4cfa-a0de-6ba6f1b6fc84"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\r\n",
        "# Combine the results across all batches. \r\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\r\n",
        "\r\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\r\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\r\n",
        "\r\n",
        "# Combine the correct labels for each batch into a single list.\r\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\r\n",
        "\r\n",
        "\r\n",
        "matrix = confusion_matrix(flat_true_labels,flat_predictions)\r\n",
        "print(matrix)\r\n",
        "score = accuracy_score(flat_true_labels,flat_predictions)\r\n",
        "print(score)\r\n",
        "report = classification_report(flat_true_labels, flat_predictions)\r\n",
        "print(report)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 31  34]\n",
            " [ 36 119]]\n",
            "0.6818181818181818\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.48      0.47        65\n",
            "           1       0.78      0.77      0.77       155\n",
            "\n",
            "    accuracy                           0.68       220\n",
            "   macro avg       0.62      0.62      0.62       220\n",
            "weighted avg       0.68      0.68      0.68       220\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS1W4S-BjNQ9",
        "outputId": "07b6d561-fa25-4548-ed14-0465edda6568"
      },
      "source": [
        "flat_predictions"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTSzDsEVjWbl"
      },
      "source": [
        "df_test['bert_pred'] = flat_predictions"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "Ny0f0t99kExF",
        "outputId": "48cac48a-2dd7-435b-df22-02eca3f3d77c"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original curator</th>\n",
              "      <th>keep</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>if edge, edge type (causes or inhibits/inhibited by) ?</th>\n",
              "      <th>Nikita_has_cause_effect</th>\n",
              "      <th>Shweta_has_cause_effect</th>\n",
              "      <th>key word that indicates edge type</th>\n",
              "      <th>if edge, node(s) 1 [start node(s)]</th>\n",
              "      <th>if edge, node(s) 2 [end node(s)]</th>\n",
              "      <th>Easy / Hard Label</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>bert_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kameron</td>\n",
              "      <td>yes</td>\n",
              "      <td>Record downpours in Tennessee provoked a state...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>provoked</td>\n",
              "      <td>record downpours</td>\n",
              "      <td>state of emergency</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kameron</td>\n",
              "      <td>yes</td>\n",
              "      <td>In California, heavy precipitation damaged tho...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>unclear--it's just the way the sentence has di...</td>\n",
              "      <td>heavy precipitation</td>\n",
              "      <td>damaged buildings</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kameron</td>\n",
              "      <td>yes</td>\n",
              "      <td>Extreme rain events have devastated communitie...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>have</td>\n",
              "      <td>extreme rain events</td>\n",
              "      <td>devastated communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kameron</td>\n",
              "      <td>yes</td>\n",
              "      <td>More than 70% of the planet’s surface is water...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>as the ... more (and also use of comma?)</td>\n",
              "      <td>[increase in] warming world</td>\n",
              "      <td>more water evaporating from oceans, lakes, and...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kameron</td>\n",
              "      <td>yes</td>\n",
              "      <td>Every 1°F rise also allows the atmosphere to h...</td>\n",
              "      <td>causes_or_promotes</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>allows</td>\n",
              "      <td>[increase in] rise in temperature</td>\n",
              "      <td>[increase in] atmosphere holding more water vapor</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>new_sampled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Climate scientists have correlated the growing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>new_sampled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>By mid-century, the annual area burned in the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>new_sampled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wildfire season can spark anytime throughout t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>new_sampled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Can rain cause more fire?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>new_sampled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wet vegetation doesn’t burn.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>220 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    original curator keep  ... Unnamed: 11 bert_pred\n",
              "0            Kameron  yes  ...         NaN         1\n",
              "1            Kameron  yes  ...         NaN         1\n",
              "2            Kameron  yes  ...         NaN         1\n",
              "3            Kameron  yes  ...         NaN         0\n",
              "4            Kameron  yes  ...         NaN         0\n",
              "..               ...  ...  ...         ...       ...\n",
              "215      new_sampled  NaN  ...         NaN         1\n",
              "216      new_sampled  NaN  ...         NaN         0\n",
              "217      new_sampled  NaN  ...         NaN         0\n",
              "218      new_sampled  NaN  ...         NaN         1\n",
              "219      new_sampled  NaN  ...         NaN         0\n",
              "\n",
              "[220 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUfejdvukF01"
      },
      "source": [
        "df_test.to_excel('bertPred_on_val_set.xlsx', columns = df_test.columns)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shNQYQuYkc3u",
        "outputId": "ac2a8863-9993-4cb2-965c-831f52223353"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\r\n",
        "\r\n",
        "output_dir = './causalRel/'\r\n",
        "\r\n",
        "# Create output directory if needed\r\n",
        "if not os.path.exists(output_dir):\r\n",
        "    os.makedirs(output_dir)\r\n",
        "\r\n",
        "print(\"Saving model to %s\" % output_dir)\r\n",
        "\r\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\r\n",
        "# They can then be reloaded using `from_pretrained()`\r\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\r\n",
        "model_to_save.save_pretrained(output_dir)\r\n",
        "tokenizer.save_pretrained(output_dir)\r\n",
        "\r\n",
        "# Good practice: save your training arguments together with the trained model\r\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./causalRel/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./causalRel/vocab.txt',\n",
              " './causalRel/special_tokens_map.json',\n",
              " './causalRel/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COXAXervmgiq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}